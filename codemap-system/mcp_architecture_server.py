#!/usr/bin/env python3
"""
MCP Architecture Server - –Ü–Ω—Ç–µ–≥—Ä–∞—Ü—ñ—è –∞—Ä—Ö—ñ—Ç–µ–∫—Ç—É—Ä–Ω–æ—ó —Å–∏—Å—Ç–µ–º–∏ –∑ Windsurf
–ó–∞–±–µ–∑–ø–µ—á—É—î –ø–æ—Å—Ç—ñ–π–Ω–∏–π –º–æ–Ω—ñ—Ç–æ—Ä–∏–Ω–≥ –∞—Ä—Ö—ñ—Ç–µ–∫—Ç—É—Ä–∏ —Ç–∞ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ—ó –¥–ª—è —Ä–æ–∑—Ä–æ–±–Ω–∏–∫–∞
"""

import json
import sys
import os
from pathlib import Path
from typing import Any, Dict, List, Optional
from datetime import datetime
import logging
from dotenv import load_dotenv

# –î–æ–¥–∞—î–º–æ codemap-system –¥–æ PYTHONPATH
sys.path.insert(0, str(Path(__file__).parent))

from architecture_mapper import ArchitectureMapper, FileStatus
from mcp_architecture_tools import MCPArchitectureTools


class ArchitectureAnalysisServer:
    """MCP —Å–µ—Ä–≤–µ—Ä –¥–ª—è –∞—Ä—Ö—ñ—Ç–µ–∫—Ç—É—Ä–Ω–æ–≥–æ –∞–Ω–∞–ª—ñ–∑—É"""
    
    def __init__(self):
        # –ó–∞–≤–∞–Ω—Ç–∞–∂—É—î–º–æ .env.architecture –∑ –ø–∞–ø–∫–∏ —Å–µ—Ä–≤–µ—Ä–∞
        env_path = Path(__file__).parent / '.env.architecture'
        if env_path.exists():
            load_dotenv(env_path)
        
        # –ß–∏—Ç–∞—î–º–æ PROJECT_ROOT –∑ .env.architecture
        project_root = os.environ.get('PROJECT_ROOT', '..')
        
        # –Ø–∫—â–æ –≤—ñ–¥–Ω–æ—Å–Ω–∏–π —à–ª—è—Ö, —Ä–æ–±–∏–º–æ –π–æ–≥–æ –∞–±—Å–æ–ª—é—Ç–Ω–∏–º –≤—ñ–¥ codemap-system
        if not os.path.isabs(project_root):
            project_root = Path(__file__).parent / project_root
        
        self.project_root = Path(project_root).resolve()
        self.codemap_dir = Path(__file__).parent
        self.reports_dir = self.codemap_dir / "reports"
        self.reports_dir.mkdir(parents=True, exist_ok=True)
        
        # –Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑—É—î–º–æ –∞—Ä—Ö—ñ—Ç–µ–∫—Ç—É—Ä–Ω—ñ —ñ–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∏
        self.arch_tools = MCPArchitectureTools(self.project_root)
        self.mapper = ArchitectureMapper(self.project_root)
        
        # –ö–µ—à –∞—Ä—Ö—ñ—Ç–µ–∫—Ç—É—Ä–∏
        self.architecture_cache = None
        self.last_analysis_time = None
        
        # –ù–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è –ª–æ–≥—É–≤–∞–Ω–Ω—è
        self._setup_logging()
        
        self.tools = self._initialize_architecture_tools()
    
    def _setup_logging(self):
        """–ù–∞–ª–∞—à—Ç—É–≤–∞—Ç–∏ –ª–æ–≥—É–≤–∞–Ω–Ω—è"""
        logs_dir = self.codemap_dir / "logs"
        logs_dir.mkdir(parents=True, exist_ok=True)
        
        log_file = logs_dir / "architecture_server.log"
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler(log_file),
                logging.StreamHandler(sys.stderr)
            ]
        )
        self.logger = logging.getLogger(__name__)
    
    def _initialize_architecture_tools(self) -> List[Dict[str, Any]]:
        """–Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑—É–≤–∞—Ç–∏ –∞—Ä—Ö—ñ—Ç–µ–∫—Ç—É—Ä–Ω—ñ —ñ–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∏"""
        return [
            {
                "name": "get_architecture_overview",
                "description": "–û—Ç—Ä–∏–º–∞—Ç–∏ –æ–≥–ª—è–¥ –∞—Ä—Ö—ñ—Ç–µ–∫—Ç—É—Ä–∏: –∞–∫—Ç–∏–≤–Ω—ñ —Ñ–∞–π–ª–∏, –Ω–µ–≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–≤–∞–Ω—ñ, –∑–¥–æ—Ä–æ–≤'—è —Å–∏—Å—Ç–µ–º–∏",
                "inputSchema": {
                    "type": "object",
                    "properties": {}
                }
            },
            {
                "name": "analyze_file_status",
                "description": "–ê–Ω–∞–ª—ñ–∑—É–≤–∞—Ç–∏ —Å—Ç–∞—Ç—É—Å –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ —Ñ–∞–π–ª—É: –∑–∞–ª–µ–∂–Ω–æ—Å—Ç—ñ, –∑–∞–ª–µ–∂–Ω—ñ —Ñ–∞–π–ª–∏, –∑–¥–æ—Ä–æ–≤'—è",
                "inputSchema": {
                    "type": "object",
                    "properties": {
                        "file_path": {"type": "string", "description": "–®–ª—è—Ö –¥–æ —Ñ–∞–π–ª—É"}
                    },
                    "required": ["file_path"]
                }
            },
            {
                "name": "detect_deprecated_files",
                "description": "–í–∏—è–≤–∏—Ç–∏ –∑–∞—Å—Ç–∞—Ä—ñ–ª—ñ —Ñ–∞–π–ª–∏: —è–∫—ñ –Ω–µ –∑–º—ñ–Ω—é–≤–∞–ª–∏—Å—è –¥–æ–≤–≥–æ, –º–∞—é—Ç—å –ø—Ä–æ–±–ª–µ–º–∏",
                "inputSchema": {
                    "type": "object",
                    "properties": {
                        "days_threshold": {"type": "integer", "description": "–ü–æ—Ä—ñ–≥ –¥–Ω—ñ–≤ –±–µ–∑ –∑–º—ñ–Ω"}
                    }
                }
            },
            {
                "name": "detect_unused_files",
                "description": "–í–∏—è–≤–∏—Ç–∏ –Ω–µ–≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–≤–∞–Ω—ñ —Ñ–∞–π–ª–∏: –Ω–∞ —è–∫—ñ –Ω—ñ—Ö—Ç–æ –Ω–µ –ø–æ—Å–∏–ª–∞—î—Ç—å—Å—è",
                "inputSchema": {
                    "type": "object",
                    "properties": {}
                }
            },
            {
                "name": "detect_duplicates",
                "description": "–í–∏—è–≤–∏—Ç–∏ –¥—É–±–ª—ñ–∫–∞—Ç–∏ –∫–æ–¥—É —Ç–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏",
                "inputSchema": {
                    "type": "object",
                    "properties": {
                        "directory": {"type": "string", "description": "–î–∏—Ä–µ–∫—Ç–æ—Ä—ñ—è –¥–ª—è –∞–Ω–∞–ª—ñ–∑—É"}
                    }
                }
            },
            {
                "name": "detect_circular_dependencies",
                "description": "–í–∏—è–≤–∏—Ç–∏ —Ü–∏–∫–ª—ñ—á–Ω—ñ –∑–∞–ª–µ–∂–Ω–æ—Å—Ç—ñ –≤ –∞—Ä—Ö—ñ—Ç–µ–∫—Ç—É—Ä—ñ",
                "inputSchema": {
                    "type": "object",
                    "properties": {}
                }
            },
            {
                "name": "get_dependency_graph",
                "description": "–û—Ç—Ä–∏–º–∞—Ç–∏ –≥—Ä–∞—Ñ –∑–∞–ª–µ–∂–Ω–æ—Å—Ç–µ–π –¥–ª—è —Ñ–∞–π–ª—É",
                "inputSchema": {
                    "type": "object",
                    "properties": {
                        "file_path": {"type": "string", "description": "–®–ª—è—Ö –¥–æ —Ñ–∞–π–ª—É"},
                        "depth": {"type": "integer", "description": "–ì–ª–∏–±–∏–Ω–∞ –≥—Ä–∞—Ñ—É"}
                    },
                    "required": ["file_path"]
                }
            },
            {
                "name": "get_architecture_health",
                "description": "–û—Ç—Ä–∏–º–∞—Ç–∏ –æ—Ü—ñ–Ω–∫—É –∑–¥–æ—Ä–æ–≤'—è –∞—Ä—Ö—ñ—Ç–µ–∫—Ç—É—Ä–∏ —Ç–∞ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ—ó",
                "inputSchema": {
                    "type": "object",
                    "properties": {}
                }
            },
            {
                "name": "get_refactoring_recommendations",
                "description": "–û—Ç—Ä–∏–º–∞—Ç–∏ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ—ó –¥–ª—è —Ä–µ—Ñ–∞–∫—Ç–æ—Ä–∏–Ω–≥—É –Ω–∞ –æ—Å–Ω–æ–≤—ñ –∞–Ω–∞–ª—ñ–∑—É",
                "inputSchema": {
                    "type": "object",
                    "properties": {
                        "priority": {"type": "string", "enum": ["low", "medium", "high"]}
                    }
                }
            },
            {
                "name": "analyze_layer",
                "description": "–ê–Ω–∞–ª—ñ–∑—É–≤–∞—Ç–∏ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–∏–π —à–∞—Ä –∞—Ä—Ö—ñ—Ç–µ–∫—Ç—É—Ä–∏",
                "inputSchema": {
                    "type": "object",
                    "properties": {
                        "layer_name": {"type": "string", "description": "–ù–∞–∑–≤–∞ —à–∞—Ä—É"}
                    },
                    "required": ["layer_name"]
                }
            },
            {
                "name": "get_file_impact",
                "description": "–û—Ç—Ä–∏–º–∞—Ç–∏ –≤–ø–ª–∏–≤ –∑–º—ñ–Ω —Ñ–∞–π–ª—É –Ω–∞ —ñ–Ω—à—ñ –º–æ–¥—É–ª—ñ",
                "inputSchema": {
                    "type": "object",
                    "properties": {
                        "file_path": {"type": "string", "description": "–®–ª—è—Ö –¥–æ —Ñ–∞–π–ª—É"}
                    },
                    "required": ["file_path"]
                }
            },
            {
                "name": "export_architecture_report",
                "description": "–ï–∫—Å–ø–æ—Ä—Ç—É–≤–∞—Ç–∏ –¥–µ—Ç–∞–ª—å–Ω–∏–π –∑–≤—ñ—Ç –∞—Ä—Ö—ñ—Ç–µ–∫—Ç—É—Ä–∏",
                "inputSchema": {
                    "type": "object",
                    "properties": {
                        "format": {"type": "string", "enum": ["json", "html", "markdown"]}
                    }
                }
            }
        ]
    
    def _ensure_architecture_cached(self):
        """–ü–µ—Ä–µ–∫–æ–Ω–∞—Ç–∏—Å—è, —â–æ –∞—Ä—Ö—ñ—Ç–µ–∫—Ç—É—Ä–∞ –ø—Ä–æ–∞–Ω–∞–ª—ñ–∑–æ–≤–∞–Ω–∞"""
        if self.architecture_cache is None:
            self.logger.info("–ê–Ω–∞–ª—ñ–∑ –∞—Ä—Ö—ñ—Ç–µ–∫—Ç—É—Ä–∏...")
            self.architecture_cache = self.mapper.analyze_architecture(max_depth=5)
            self.last_analysis_time = datetime.now()
            self.logger.info("–ê—Ä—Ö—ñ—Ç–µ–∫—Ç—É—Ä–∞ –ø—Ä–æ–∞–Ω–∞–ª—ñ–∑–æ–≤–∞–Ω–∞")
    
    def handle_tool_call(self, tool_name: str, arguments: Dict[str, Any]) -> str:
        """–û–±—Ä–æ–±–∏—Ç–∏ –≤–∏–∫–ª–∏–∫ —ñ–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—É"""
        try:
            if tool_name == "get_architecture_overview":
                return self._get_architecture_overview()
            elif tool_name == "analyze_file_status":
                file_path = arguments.get("file_path", "")
                return self._analyze_file_status(file_path)
            elif tool_name == "detect_deprecated_files":
                days = arguments.get("days_threshold", 90)
                return self._detect_deprecated_files(days)
            elif tool_name == "detect_unused_files":
                return self._detect_unused_files()
            elif tool_name == "detect_duplicates":
                directory = arguments.get("directory")
                return self._detect_duplicates(directory)
            elif tool_name == "detect_circular_dependencies":
                return self._detect_circular_dependencies()
            elif tool_name == "get_dependency_graph":
                file_path = arguments.get("file_path", "")
                depth = arguments.get("depth", 2)
                return self._get_dependency_graph(file_path, depth)
            elif tool_name == "get_architecture_health":
                return self._get_architecture_health()
            elif tool_name == "get_refactoring_recommendations":
                priority = arguments.get("priority", "medium")
                return self._get_refactoring_recommendations(priority)
            elif tool_name == "analyze_layer":
                layer_name = arguments.get("layer_name", "")
                return self._analyze_layer(layer_name)
            elif tool_name == "get_file_impact":
                file_path = arguments.get("file_path", "")
                return self._get_file_impact(file_path)
            elif tool_name == "export_architecture_report":
                format_type = arguments.get("format", "json")
                return self._export_architecture_report(format_type)
            else:
                return json.dumps({"error": f"Unknown tool: {tool_name}"})
        except Exception as e:
            self.logger.error(f"–ü–æ–º–∏–ª–∫–∞ –≤ {tool_name}: {e}", exc_info=True)
            return json.dumps({"error": str(e)})
    
    def _get_architecture_overview(self) -> str:
        """–û—Ç—Ä–∏–º–∞—Ç–∏ –æ–≥–ª—è–¥ –∞—Ä—Ö—ñ—Ç–µ–∫—Ç—É—Ä–∏"""
        self._ensure_architecture_cached()
        
        if self.architecture_cache is None or self.last_analysis_time is None:
            return json.dumps({"error": "Architecture not analyzed yet"})
        
        overview = {
            "timestamp": self.last_analysis_time.isoformat(),
            "statistics": self.architecture_cache.get("statistics", {}),
            "health_score": self.architecture_cache.get("health_score", {}),
            "summary": {
                "total_files": self.architecture_cache.get("statistics", {}).get("total_files", 0),
                "active_files": self.architecture_cache.get("statistics", {}).get("active_files", 0),
                "deprecated_files": self.architecture_cache.get("statistics", {}).get("deprecated_files", 0),
                "unused_files": self.architecture_cache.get("statistics", {}).get("unused_files", 0),
            }
        }
        
        return json.dumps(overview, indent=2, ensure_ascii=False)
    
    def _analyze_file_status(self, file_path: str) -> str:
        """–ê–Ω–∞–ª—ñ–∑—É–≤–∞—Ç–∏ —Å—Ç–∞—Ç—É—Å —Ñ–∞–π–ª—É"""
        self._ensure_architecture_cached()
        
        if self.architecture_cache is None:
            return json.dumps({"error": "Architecture not analyzed yet"})
        
        if file_path not in self.architecture_cache.get("files", {}):
            return json.dumps({"error": f"File not found: {file_path}"})
        
        file_info = self.architecture_cache["files"][file_path]
        
        status_info = {
            "file": file_path,
            "status": file_info.get("status"),
            "size": file_info.get("size"),
            "lines": file_info.get("lines"),
            "last_modified": file_info.get("last_modified"),
            "functions_count": file_info.get("functions_count"),
            "classes_count": file_info.get("classes_count"),
            "dependencies": self.architecture_cache.get("dependencies", {}).get(file_path, []),
            "dependents": self.architecture_cache.get("reverse_dependencies", {}).get(file_path, []),
        }
        
        return json.dumps(status_info, indent=2, ensure_ascii=False)
    
    def _detect_deprecated_files(self, days_threshold: int) -> str:
        """–í–∏—è–≤–∏—Ç–∏ –∑–∞—Å—Ç–∞—Ä—ñ–ª—ñ —Ñ–∞–π–ª–∏"""
        self._ensure_architecture_cached()
        
        if self.architecture_cache is None:
            return json.dumps({"error": "Architecture not analyzed yet"})
        
        deprecated = []
        for file_path, file_info in self.architecture_cache.get("files", {}).items():
            if file_info.get("status") == FileStatus.DEPRECATED:
                deprecated.append({
                    "file": file_path,
                    "reason": file_info.get("deprecation_reason"),
                    "last_modified": file_info.get("last_modified")
                })
        
        return json.dumps({
            "deprecated_files": deprecated,
            "count": len(deprecated)
        }, indent=2, ensure_ascii=False)
    
    def _detect_unused_files(self) -> str:
        """–í–∏—è–≤–∏—Ç–∏ –Ω–µ–≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–≤–∞–Ω—ñ —Ñ–∞–π–ª–∏"""
        self._ensure_architecture_cached()
        
        if self.architecture_cache is None:
            return json.dumps({"error": "Architecture not analyzed yet"})
        
        unused = []
        for file_path, file_info in self.architecture_cache.get("files", {}).items():
            if file_info.get("status") == FileStatus.UNUSED:
                unused.append({
                    "file": file_path,
                    "size": file_info.get("size"),
                    "lines": file_info.get("lines")
                })
        
        return json.dumps({
            "unused_files": unused,
            "count": len(unused)
        }, indent=2, ensure_ascii=False)
    
    def _detect_duplicates(self, directory: Optional[str] = None) -> str:
        """–í–∏—è–≤–∏—Ç–∏ –¥—É–±–ª—ñ–∫–∞—Ç–∏"""
        # –¶–µ –±—É–¥–µ —Ä–µ–∞–ª—ñ–∑–æ–≤–∞–Ω–æ —á–µ—Ä–µ–∑ duplication_analyzer
        return json.dumps({
            "duplicates": [],
            "message": "–î—É–±–ª—ñ–∫–∞—Ç–∏ –±—É–¥—É—Ç—å –≤–∏—è–≤–ª–µ–Ω—ñ —á–µ—Ä–µ–∑ duplication_analyzer"
        }, indent=2, ensure_ascii=False)
    
    def _detect_circular_dependencies(self) -> str:
        """–í–∏—è–≤–∏—Ç–∏ —Ü–∏–∫–ª—ñ—á–Ω—ñ –∑–∞–ª–µ–∂–Ω–æ—Å—Ç—ñ"""
        self._ensure_architecture_cached()
        
        if self.architecture_cache is None:
            return json.dumps({"error": "Architecture not analyzed yet"})
        
        cycles = self.architecture_cache.get("circular_dependencies", [])
        
        return json.dumps({
            "circular_dependencies": cycles,
            "count": len(cycles)
        }, indent=2, ensure_ascii=False)
    
    def _get_dependency_graph(self, file_path: str, depth: int) -> str:
        """–û—Ç—Ä–∏–º–∞—Ç–∏ –≥—Ä–∞—Ñ –∑–∞–ª–µ–∂–Ω–æ—Å—Ç–µ–π"""
        self._ensure_architecture_cached()
        
        if self.architecture_cache is None:
            return json.dumps({"error": "Architecture not analyzed yet"})
        
        graph = {
            "root": file_path,
            "depth": depth,
            "nodes": {},
            "edges": []
        }
        
        # –ë—É–¥—É—î–º–æ –≥—Ä–∞—Ñ —Ä–µ–∫—É—Ä—Å–∏–≤–Ω–æ
        self._build_graph_recursive(file_path, graph, depth, 0)
        
        return json.dumps(graph, indent=2, ensure_ascii=False)
    
    def _build_graph_recursive(self, file_path: str, graph: Dict, max_depth: int, current_depth: int):
        """–†–µ–∫—É—Ä—Å–∏–≤–Ω–æ –±—É–¥—É–≤–∞—Ç–∏ –≥—Ä–∞—Ñ"""
        if current_depth >= max_depth or file_path in graph["nodes"]:
            return
        
        if self.architecture_cache is None:
            return
        
        if file_path not in self.architecture_cache.get("files", {}):
            return
        
        file_info = self.architecture_cache["files"][file_path]
        graph["nodes"][file_path] = {
            "status": file_info.get("status"),
            "lines": file_info.get("lines"),
            "depth": current_depth
        }
        
        deps = self.architecture_cache.get("dependencies", {}).get(file_path, [])
        for dep in deps:
            graph["edges"].append({"from": file_path, "to": dep})
            self._build_graph_recursive(dep, graph, max_depth, current_depth + 1)
    
    def _get_architecture_health(self) -> str:
        """–û—Ç—Ä–∏–º–∞—Ç–∏ –æ—Ü—ñ–Ω–∫—É –∑–¥–æ—Ä–æ–≤'—è –∞—Ä—Ö—ñ—Ç–µ–∫—Ç—É—Ä–∏"""
        self._ensure_architecture_cached()
        
        if self.architecture_cache is None:
            return json.dumps({"error": "Architecture not analyzed yet"})
        
        health = self.architecture_cache.get("health_score", {})
        
        return json.dumps({
            "health": health,
            "recommendations": self._generate_health_recommendations(health)
        }, indent=2, ensure_ascii=False)
    
    def _generate_health_recommendations(self, health: Dict) -> List[str]:
        """–ì–µ–Ω–µ—Ä—É–≤–∞—Ç–∏ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ—ó –Ω–∞ –æ—Å–Ω–æ–≤—ñ –∑–¥–æ—Ä–æ–≤'—è"""
        recommendations = []
        score = health.get("score", 0)
        
        if score < 50:
            recommendations.append("‚ö†Ô∏è –ê—Ä—Ö—ñ—Ç–µ–∫—Ç—É—Ä–∞ –ø–æ—Ç—Ä–µ–±—É—î —Å–µ—Ä–π–æ–∑–Ω–æ–≥–æ —Ä–µ—Ñ–∞–∫—Ç–æ—Ä–∏–Ω–≥—É")
        elif score < 70:
            recommendations.append("‚ö†Ô∏è –ê—Ä—Ö—ñ—Ç–µ–∫—Ç—É—Ä–∞ –º–∞—î –ø—Ä–æ–±–ª–µ–º–∏, —Ä–µ–∫–æ–º–µ–Ω–¥—É—î—Ç—å—Å—è –ø–æ–∫—Ä–∞—â–µ–Ω–Ω—è")
        else:
            recommendations.append("‚úÖ –ê—Ä—Ö—ñ—Ç–µ–∫—Ç—É—Ä–∞ –≤ —Ö–æ—Ä–æ—à–æ–º—É —Å—Ç–∞–Ω—ñ")
        
        return recommendations
    
    def _get_refactoring_recommendations(self, priority: str) -> str:
        """–û—Ç—Ä–∏–º–∞—Ç–∏ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ—ó —Ä–µ—Ñ–∞–∫—Ç–æ—Ä–∏–Ω–≥—É"""
        self._ensure_architecture_cached()
        
        if self.architecture_cache is None:
            return json.dumps({"error": "Architecture not analyzed yet"})
        
        recommendations = {
            "priority": priority,
            "items": []
        }
        
        # –ê–Ω–∞–ª—ñ–∑—É—î–º–æ –∞—Ä—Ö—ñ—Ç–µ–∫—Ç—É—Ä—É —Ç–∞ –≥–µ–Ω–µ—Ä—É—î–º–æ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ—ó
        for file_path, file_info in self.architecture_cache.get("files", {}).items():
            if file_info.get("status") == FileStatus.DEPRECATED:
                recommendations["items"].append({
                    "file": file_path,
                    "type": "deprecated",
                    "action": "–†–æ–∑–≥–ª—è–Ω—É—Ç–∏ –≤–∏–¥–∞–ª–µ–Ω–Ω—è –∞–±–æ –æ–Ω–æ–≤–ª–µ–Ω–Ω—è"
                })
            elif file_info.get("status") == FileStatus.UNUSED:
                recommendations["items"].append({
                    "file": file_path,
                    "type": "unused",
                    "action": "–†–æ–∑–≥–ª—è–Ω—É—Ç–∏ –≤–∏–¥–∞–ª–µ–Ω–Ω—è"
                })
        
        return json.dumps(recommendations, indent=2, ensure_ascii=False)
    
    def _analyze_layer(self, layer_name: str) -> str:
        """–ê–Ω–∞–ª—ñ–∑—É–≤–∞—Ç–∏ —à–∞—Ä –∞—Ä—Ö—ñ—Ç–µ–∫—Ç—É—Ä–∏"""
        self._ensure_architecture_cached()
        
        if self.architecture_cache is None:
            return json.dumps({"error": "Architecture not analyzed yet"})
        
        layer_info = self.architecture_cache.get("layers", {}).get(layer_name, {})
        
        return json.dumps({
            "layer": layer_name,
            "info": layer_info
        }, indent=2, ensure_ascii=False)
    
    def _get_file_impact(self, file_path: str) -> str:
        """–û—Ç—Ä–∏–º–∞—Ç–∏ –≤–ø–ª–∏–≤ –∑–º—ñ–Ω —Ñ–∞–π–ª—É"""
        self._ensure_architecture_cached()
        
        if self.architecture_cache is None:
            return json.dumps({"error": "Architecture not analyzed yet"})
        
        dependents = self.architecture_cache.get("reverse_dependencies", {}).get(file_path, [])
        
        return json.dumps({
            "file": file_path,
            "affected_files": dependents,
            "impact_count": len(dependents)
        }, indent=2, ensure_ascii=False)
    
    def _export_architecture_report(self, format: str) -> str:
        """–ï–∫—Å–ø–æ—Ä—Ç—É–≤–∞—Ç–∏ –∑–≤—ñ—Ç –∞—Ä—Ö—ñ—Ç–µ–∫—Ç—É—Ä–∏"""
        self._ensure_architecture_cached()
        
        report_path = self.reports_dir / f"architecture_report.{format}"
        
        if format == "json":
            with open(report_path, 'w', encoding='utf-8') as f:
                json.dump(self.architecture_cache, f, indent=2, ensure_ascii=False)
        elif format == "html":
            # –ì–µ–Ω–µ—Ä—É—î–º–æ HTML –∑–≤—ñ—Ç
            html_content = self._generate_html_report()
            with open(report_path, 'w', encoding='utf-8') as f:
                f.write(html_content)
        elif format == "markdown":
            # –ì–µ–Ω–µ—Ä—É—î–º–æ Markdown –∑–≤—ñ—Ç
            md_content = self._generate_markdown_report()
            with open(report_path, 'w', encoding='utf-8') as f:
                f.write(md_content)
        
        return json.dumps({
            "success": True,
            "report_path": str(report_path),
            "format": format
        }, indent=2, ensure_ascii=False)
    
    def _generate_html_report(self) -> str:
        """–ì–µ–Ω–µ—Ä—É–≤–∞—Ç–∏ HTML –∑–≤—ñ—Ç"""
        if self.architecture_cache is None:
            return "<html><body>Architecture not analyzed</body></html>"
        
        stats = self.architecture_cache.get("statistics", {})
        health = self.architecture_cache.get("health_score", {})
        
        html = f"""
        <!DOCTYPE html>
        <html>
        <head>
            <title>Architecture Report</title>
            <style>
                body {{ font-family: Arial, sans-serif; margin: 20px; }}
                h1 {{ color: #333; }}
                .stat {{ margin: 10px 0; }}
                .health {{ color: {'green' if health.get('score', 0) > 70 else 'orange'}; }}
            </style>
        </head>
        <body>
            <h1>üèóÔ∏è Architecture Report</h1>
            <h2>Statistics</h2>
            <div class="stat">Total Files: {stats.get('total_files', 0)}</div>
            <div class="stat">Active Files: {stats.get('active_files', 0)}</div>
            <div class="stat">Unused Files: {stats.get('unused_files', 0)}</div>
            <h2>Health</h2>
            <div class="health">Score: {health.get('score', 0)}/100</div>
        </body>
        </html>
        """
        return html
    
    def _generate_markdown_report(self) -> str:
        """–ì–µ–Ω–µ—Ä—É–≤–∞—Ç–∏ Markdown –∑–≤—ñ—Ç"""
        if self.architecture_cache is None:
            return "# Architecture not analyzed"
        
        stats = self.architecture_cache.get("statistics", {})
        health = self.architecture_cache.get("health_score", {})
        
        md = f"""
# üèóÔ∏è Architecture Report

## Statistics
- Total Files: {stats.get('total_files', 0)}
- Active Files: {stats.get('active_files', 0)}
- Unused Files: {stats.get('unused_files', 0)}

## Health
- Score: {health.get('score', 0)}/100
"""
        return md


def main():
    """–û—Å–Ω–æ–≤–Ω–∞ —Ñ—É–Ω–∫—Ü—ñ—è MCP —Å–µ—Ä–≤–µ—Ä–∞"""
    logger = logging.getLogger(__name__)
    
    # Force fallback mode for now since MCP SDK is complex
    logger.warning("Using fallback JSON-RPC mode for compatibility")
    server = ArchitectureAnalysisServer()
    
    # –ß–∏—Ç–∞—î–º–æ JSON-RPC –∑–∞–ø–∏—Ç–∏ –∑—ñ stdin
    for line in sys.stdin:
        try:
            request = json.loads(line)
            
            if request.get("method") == "initialize":
                response = {
                    "jsonrpc": "2.0",
                    "id": request.get("id"),
                    "result": {
                        "protocolVersion": "2024-11-05",
                        "capabilities": {},
                        "serverInfo": {
                            "name": "architecture-analysis-server",
                            "version": "1.0.0"
                        }
                    }
                }
            elif request.get("method") == "tools/list":
                response = {
                    "jsonrpc": "2.0",
                    "id": request.get("id"),
                    "result": {
                        "tools": server.tools
                    }
                }
            elif request.get("method") == "tools/call":
                params = request.get("params", {})
                tool_name = params.get("name")
                arguments = params.get("arguments", {})
                
                result = server.handle_tool_call(tool_name, arguments)
                
                response = {
                    "jsonrpc": "2.0",
                    "id": request.get("id"),
                    "result": {
                        "content": [
                            {
                                "type": "text",
                                "text": result
                            }
                        ]
                    }
                }
            else:
                response = {
                    "jsonrpc": "2.0",
                    "id": request.get("id"),
                    "error": {
                        "code": -32601,
                        "message": "Method not found"
                    }
                }
            
            print(json.dumps(response))
            sys.stdout.flush()
            
        except json.JSONDecodeError:
            continue
        except Exception as e:
            logger.error(f"Error processing request: {e}")
            continue


if __name__ == "__main__":
    main()
