#!/usr/bin/env python3
"""
–ê–ù–ê–õ–Ü–ó –î–£–ë–õ–Ü–í –¢–ê –°–¢–†–£–ö–¢–£–†–ò –ü–†–û–ï–ö–¢–£
–í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î MCP —Å–µ—Ä–≤–µ—Ä –¥–ª—è –≥–ª–∏–±–æ–∫–æ–≥–æ –∞–Ω–∞–ª—ñ–∑—É
"""

import sys
import json
import os
from pathlib import Path
from collections import defaultdict
import hashlib
from typing import Dict, List, Set, Tuple, Any, Optional
import logging

# ============================================================================
# LOGGING
# ============================================================================

def setup_logging():
    """Setup logging"""
    log_dir = Path(__file__).parent.parent / "logs"
    log_dir.mkdir(parents=True, exist_ok=True)
    log_file = log_dir / "duplicates_analysis.log"
    
    logger = logging.getLogger(__name__)
    logger.setLevel(logging.DEBUG)
    logger.handlers = []
    
    handler = logging.FileHandler(log_file, encoding='utf-8')
    handler.setLevel(logging.DEBUG)
    
    formatter = logging.Formatter(
        '%(asctime)s - %(levelname)s - %(message)s',
        datefmt='%Y-%m-%d %H:%M:%S'
    )
    handler.setFormatter(formatter)
    logger.addHandler(handler)
    
    console_handler = logging.StreamHandler(sys.stdout)
    console_handler.setLevel(logging.INFO)
    console_handler.setFormatter(formatter)
    logger.addHandler(console_handler)
    
    return logger

logger = setup_logging()

# ============================================================================
# –ê–ù–ê–õ–Ü–ó –î–£–ë–õ–Ü–í
# ============================================================================

class DuplicateAnalyzer:
    """–ê–Ω–∞–ª—ñ–∑–∞—Ç–æ—Ä –¥—É–±–ª—ñ–≤ —É –ø—Ä–æ–µ–∫—Ç—ñ"""
    
    def __init__(self, project_root: str):
        self.project_root = Path(project_root)
        self.file_hashes: Dict[str, List[str]] = defaultdict(list)
        self.code_blocks: Dict[str, List[str]] = defaultdict(list)
        
        logger.info(f"üîç –Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–∞—Ü—ñ—è –∞–Ω–∞–ª—ñ–∑–∞—Ç–æ—Ä–∞ –¥—É–±–ª—ñ–≤ –¥–ª—è: {self.project_root}")
    
    def get_file_hash(self, file_path: Path) -> Optional[str]:
        """–û—Ç—Ä–∏–º–∞—Ç–∏ —Ö–µ—à —Ñ–∞–π–ª—É"""
        try:
            with open(file_path, 'rb') as f:
                return hashlib.md5(f.read()).hexdigest()
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è  –ù–µ –º–æ–∂—É –ø—Ä–æ—á–∏—Ç–∞—Ç–∏ {file_path}: {e}")
            return None
    
    def normalize_code(self, code: str) -> str:
        """–ù–æ—Ä–º–∞–ª—ñ–∑—É–≤–∞—Ç–∏ –∫–æ–¥ –¥–ª—è –ø–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è"""
        lines = []
        for line in code.split('\n'):
            if '#' in line:
                line = line[:line.index('#')]
            line = line.strip()
            if line:
                lines.append(line)
        return '\n'.join(lines)
    
    def analyze_duplicates(self) -> Dict[str, Any]:
        """–ê–Ω–∞–ª—ñ–∑—É–≤–∞—Ç–∏ –¥—É–±–ª—ñ —É –ø—Ä–æ–µ–∫—Ç—ñ"""
        logger.info("üìä –ü–æ—á–∞—Ç–æ–∫ –∞–Ω–∞–ª—ñ–∑—É –¥—É–±–ª—ñ–≤...")
        
        file_extensions = {'.py', '.js', '.ts', '.jsx', '.tsx', '.json', '.yaml', '.yml'}
        
        for file_path in self.project_root.rglob('*'):
            if file_path.is_file() and file_path.suffix in file_extensions:
                if any(part in file_path.parts for part in ['node_modules', '.git', '__pycache__', '.venv', 'venv']):
                    continue
                
                file_hash = self.get_file_hash(file_path)
                if file_hash:
                    rel_path = file_path.relative_to(self.project_root)
                    self.file_hashes[file_hash].append(str(rel_path))
        
        duplicates = {}
        for file_hash, files in self.file_hashes.items():
            if len(files) > 1:
                duplicates[file_hash] = files
        
        logger.info(f"‚úÖ –ó–Ω–∞–π–¥–µ–Ω–æ {len(duplicates)} –≥—Ä—É–ø–ø –¥—É–±–ª—ñ–≤")
        
        return {
            "total_files_analyzed": sum(len(files) for files in self.file_hashes.values()),
            "duplicate_groups": len(duplicates),
            "duplicates": duplicates,
            "duplicate_files": sum(len(files) - 1 for files in duplicates.values())
        }
    
    def find_similar_functions(self) -> Dict[str, Any]:
        """–ó–Ω–∞–π—Ç–∏ –ø–æ–¥—ñ–±–Ω—ñ —Ñ—É–Ω–∫—Ü—ñ—ó"""
        logger.info("üîé –ü–æ—à—É–∫ –ø–æ–¥—ñ–±–Ω–∏—Ö —Ñ—É–Ω–∫—Ü—ñ–π...")
        
        similar_functions: Dict[str, List[Dict[str, Any]]] = defaultdict(list)
        
        for file_path in self.project_root.rglob('*.py'):
            if any(part in file_path.parts for part in ['node_modules', '.git', '__pycache__', '.venv', 'venv']):
                continue
            
            try:
                with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                    content = f.read()
                    
                    lines = content.split('\n')
                    current_func = None
                    func_lines = []
                    
                    for i, line in enumerate(lines):
                        if line.strip().startswith('def '):
                            if current_func:
                                func_code = '\n'.join(func_lines)
                                normalized = self.normalize_code(func_code)
                                code_hash = hashlib.md5(normalized.encode()).hexdigest()
                                similar_functions[code_hash].append({
                                    'file': str(file_path.relative_to(self.project_root)),
                                    'function': current_func,
                                    'line': i - len(func_lines) + 1
                                })
                            
                            current_func = line.split('def ')[1].split('(')[0]
                            func_lines = [line]
                        elif current_func:
                            if line and not line[0].isspace() and not line.strip().startswith('#'):
                                current_func = None
                                func_lines = []
                            else:
                                func_lines.append(line)
                    
                    if current_func:
                        func_code = '\n'.join(func_lines)
                        normalized = self.normalize_code(func_code)
                        code_hash = hashlib.md5(normalized.encode()).hexdigest()
                        similar_functions[code_hash].append({
                            'file': str(file_path.relative_to(self.project_root)),
                            'function': current_func,
                            'line': len(lines) - len(func_lines) + 1
                        })
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è  –ü–æ–º–∏–ª–∫–∞ –ø—Ä–∏ –∞–Ω–∞–ª—ñ–∑—ñ {file_path}: {e}")
        
        duplicate_functions = {}
        for code_hash, functions in similar_functions.items():
            if len(functions) > 1:
                duplicate_functions[code_hash] = functions
        
        logger.info(f"‚úÖ –ó–Ω–∞–π–¥–µ–Ω–æ {len(duplicate_functions)} –≥—Ä—É–ø –ø–æ–¥—ñ–±–Ω–∏—Ö —Ñ—É–Ω–∫—Ü—ñ–π")
        
        return {
            "duplicate_function_groups": len(duplicate_functions),
            "duplicate_functions": duplicate_functions,
            "total_similar_functions": sum(len(funcs) for funcs in duplicate_functions.values())
        }

# ============================================================================
# –ê–ù–ê–õ–Ü–ó –°–¢–†–£–ö–¢–£–†–ò
# ============================================================================

class StructureAnalyzer:
    """–ê–Ω–∞–ª—ñ–∑–∞—Ç–æ—Ä —Å—Ç—Ä—É–∫—Ç—É—Ä–∏ –ø—Ä–æ–µ–∫—Ç—É"""
    
    def __init__(self, project_root: str):
        self.project_root = Path(project_root)
        self.stats = {
            'total_files': 0,
            'total_dirs': 0,
            'by_extension': defaultdict(int),
            'by_directory': defaultdict(int)
        }
        
        logger.info(f"üìÅ –Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–∞—Ü—ñ—è –∞–Ω–∞–ª—ñ–∑–∞—Ç–æ—Ä–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏ –¥–ª—è: {self.project_root}")
    
    def analyze_structure(self) -> Dict[str, Any]:
        """–ê–Ω–∞–ª—ñ–∑—É–≤–∞—Ç–∏ —Å—Ç—Ä—É–∫—Ç—É—Ä—É –ø—Ä–æ–µ–∫—Ç—É"""
        logger.info("üìä –ü–æ—á–∞—Ç–æ–∫ –∞–Ω–∞–ª—ñ–∑—É —Å—Ç—Ä—É–∫—Ç—É—Ä–∏...")
        
        ignore_patterns = {'.git', 'node_modules', '__pycache__', '.venv', 'venv', '.env', '.DS_Store'}
        
        def build_tree(path: Path, depth: int = 0) -> Optional[List]:
            if depth > 10:
                return None
            
            items: List = []
            try:
                for item in sorted(path.iterdir()):
                    if item.is_symlink():
                        logger.warning(f"‚ö†Ô∏è  –°–∏–º–≤–æ–ª—ñ—á–Ω–∏–π –ø–æ—Å–∏–ª–∞–Ω–Ω—è: {item}")
                        continue
                    
                    if item.name.startswith('.') and item.name not in {'.windsurf', '.github', '.cascade', '.config'}:
                        continue
                    if item.name in ignore_patterns:
                        continue
                    
                    if item.is_dir():
                        self.stats['total_dirs'] += 1
                        self.stats['by_directory'][str(item.relative_to(self.project_root))] += 1
                        
                        subtree = build_tree(item, depth + 1)
                        if subtree is not None:
                            items.append({
                                'name': item.name,
                                'type': 'directory',
                                'path': str(item.relative_to(self.project_root)),
                                'items': subtree
                            })
                    elif item.is_file():
                        self.stats['total_files'] += 1
                        ext = item.suffix or 'no_extension'
                        self.stats['by_extension'][ext] += 1
                        
                        try:
                            size = item.stat().st_size
                        except (OSError, FileNotFoundError):
                            size = 0
                        
                        items.append({
                            'name': item.name,
                            'type': 'file',
                            'path': str(item.relative_to(self.project_root)),
                            'size': size
                        })
            except PermissionError:
                logger.warning(f"‚ö†Ô∏è  –ù–µ–º–∞—î –¥–æ—Å—Ç—É–ø—É –¥–æ: {path}")
            
            return items
        
        tree = build_tree(self.project_root)
        
        logger.info(f"‚úÖ –ê–Ω–∞–ª—ñ–∑ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏ –∑–∞–≤–µ—Ä—à–µ–Ω–æ")
        
        return {
            'total_files': self.stats['total_files'],
            'total_directories': self.stats['total_dirs'],
            'files_by_extension': dict(self.stats['by_extension']),
            'structure_tree': tree if tree else []
        }
    
    def get_directory_sizes(self) -> Dict[str, int]:
        """–û—Ç—Ä–∏–º–∞—Ç–∏ —Ä–æ–∑–º—ñ—Ä–∏ –¥–∏—Ä–µ–∫—Ç–æ—Ä—ñ–π"""
        logger.info("üìè –†–æ–∑—Ä–∞—Ö—É–Ω–æ–∫ —Ä–æ–∑–º—ñ—Ä—ñ–≤ –¥–∏—Ä–µ–∫—Ç–æ—Ä—ñ–π...")
        
        dir_sizes: Dict[str, int] = {}
        
        def get_size(path: Path) -> int:
            total = 0
            try:
                for item in path.rglob('*'):
                    if item.is_file() and not item.is_symlink():
                        try:
                            total += item.stat().st_size
                        except OSError as e:
                            logger.warning(f"‚ö†Ô∏è  –ü–æ–º–∏–ª–∫–∞ –ø—Ä–∏ –æ—Ç—Ä–∏–º–∞–Ω–Ω—ñ —Ä–æ–∑–º—ñ—Ä—É —Ñ–∞–π–ª—É {item}: {e}")
            except PermissionError:
                pass
            return total
        
        for item in self.project_root.iterdir():
            if item.is_dir() and not item.name.startswith('.') and not item.is_symlink():
                try:
                    size = get_size(item)
                    dir_sizes[item.name] = size
                except Exception as e:
                    logger.warning(f"‚ö†Ô∏è  –ü–æ–º–∏–ª–∫–∞ –ø—Ä–∏ —Ä–æ–∑—Ä–∞—Ö—É–Ω–∫—É —Ä–æ–∑–º—ñ—Ä—É –¥–∏—Ä–µ–∫—Ç–æ—Ä—ñ—ó {item}: {e}")
        
        return dict(sorted(dir_sizes.items(), key=lambda x: x[1], reverse=True))

# ============================================================================
# –û–°–ù–û–í–ù–ê –§–£–ù–ö–¶–Ü–Ø
# ============================================================================

def main():
    """–û—Å–Ω–æ–≤–Ω–∞ —Ñ—É–Ω–∫—Ü—ñ—è"""
    project_root = os.environ.get('PROJECT_ROOT', '/Users/dev/Documents/GitHub/atlas4')
    
    logger.info("=" * 80)
    logger.info("üöÄ –ê–ù–ê–õ–Ü–ó –î–£–ë–õ–Ü–í –¢–ê –°–¢–†–£–ö–¢–£–†–ò –ü–†–û–ï–ö–¢–£")
    logger.info("=" * 80)
    
    # –ê–Ω–∞–ª—ñ–∑ –¥—É–±–ª—ñ–≤
    logger.info("\nüìä –§–ê–ó–ê 1: –ê–ù–ê–õ–Ü–ó –î–£–ë–õ–Ü–í")
    logger.info("-" * 80)
    
    dup_analyzer = DuplicateAnalyzer(project_root)
    duplicates_result = dup_analyzer.analyze_duplicates()
    similar_funcs_result = dup_analyzer.find_similar_functions()
    
    # –ê–Ω–∞–ª—ñ–∑ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏
    logger.info("\nüìÅ –§–ê–ó–ê 2: –ê–ù–ê–õ–Ü–ó –°–¢–†–£–ö–¢–£–†–ò")
    logger.info("-" * 80)
    
    struct_analyzer = StructureAnalyzer(project_root)
    structure_result = struct_analyzer.analyze_structure()
    dir_sizes = struct_analyzer.get_directory_sizes()
    
    # –ó–±—ñ—Ä–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤
    results = {
        'timestamp': str(Path(__file__).stat().st_mtime),
        'project_root': project_root,
        'duplicates': duplicates_result,
        'similar_functions': similar_funcs_result,
        'structure': structure_result,
        'directory_sizes': dir_sizes
    }
    
    # –ó–±–µ—Ä–µ–∂–µ–Ω–Ω—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤
    reports_dir = Path(project_root) / 'reports'
    reports_dir.mkdir(parents=True, exist_ok=True)
    
    report_file = reports_dir / 'duplicates_and_structure_analysis.json'
    with open(report_file, 'w', encoding='utf-8') as f:
        json.dump(results, f, indent=2, ensure_ascii=False)
    
    logger.info(f"\n‚úÖ –ó–≤—ñ—Ç –∑–±–µ—Ä–µ–∂–µ–Ω–æ: {report_file}")
    
    # –í–∏–≤—ñ–¥ —Ä–µ–∑—é–º–µ
    logger.info("\n" + "=" * 80)
    logger.info("üìã –†–ï–ó–Æ–ú–ï –ê–ù–ê–õ–Ü–ó–£")
    logger.info("=" * 80)
    
    logger.info(f"\nüìä –î–£–ë–õ–Ü:")
    logger.info(f"  ‚Ä¢ –í—Å—å–æ–≥–æ —Ñ–∞–π–ª—ñ–≤ –ø—Ä–æ–∞–Ω–∞–ª—ñ–∑–æ–≤–∞–Ω–æ: {duplicates_result['total_files_analyzed']}")
    logger.info(f"  ‚Ä¢ –ì—Ä—É–ø –¥—É–±–ª—ñ–≤: {duplicates_result['duplicate_groups']}")
    logger.info(f"  ‚Ä¢ –î—É–±–ª—ñ–≤ —Ñ–∞–π–ª—ñ–≤: {duplicates_result['duplicate_files']}")
    
    logger.info(f"\nüîé –ü–û–î–Ü–ë–ù–Ü –§–£–ù–ö–¶–Ü–á:")
    logger.info(f"  ‚Ä¢ –ì—Ä—É–ø –ø–æ–¥—ñ–±–Ω–∏—Ö —Ñ—É–Ω–∫—Ü—ñ–π: {similar_funcs_result['duplicate_function_groups']}")
    logger.info(f"  ‚Ä¢ –í—Å—å–æ–≥–æ –ø–æ–¥—ñ–±–Ω–∏—Ö —Ñ—É–Ω–∫—Ü—ñ–π: {similar_funcs_result['total_similar_functions']}")
    
    logger.info(f"\nüìÅ –°–¢–†–£–ö–¢–£–†–ê:")
    logger.info(f"  ‚Ä¢ –í—Å—å–æ–≥–æ —Ñ–∞–π–ª—ñ–≤: {structure_result['total_files']}")
    logger.info(f"  ‚Ä¢ –í—Å—å–æ–≥–æ –¥–∏—Ä–µ–∫—Ç–æ—Ä—ñ–π: {structure_result['total_directories']}")
    logger.info(f"  ‚Ä¢ –¢–∏–ø–∏ —Ñ–∞–π–ª—ñ–≤: {len(structure_result['files_by_extension'])}")
    
    logger.info(f"\nüìè –¢–û–ü 10 –ù–ê–ô–ë–Ü–õ–¨–®–ò–• –î–ò–†–ï–ö–¢–û–†–Ü–ô:")
    for i, (dir_name, size) in enumerate(list(dir_sizes.items())[:10], 1):
        size_mb = size / (1024 * 1024)
        logger.info(f"  {i}. {dir_name}: {size_mb:.2f} MB")
    
    logger.info("\n" + "=" * 80)
    logger.info("‚úÖ –ê–ù–ê–õ–Ü–ó –ó–ê–í–ï–†–®–ï–ù–û")
    logger.info("=" * 80)
    
    return results

if __name__ == '__main__':
    main()
