# ü§ù –†–æ–∑—Ä–æ–±–∫–∞ —Ç–∞ —Ä–æ–∑—à–∏—Ä–µ–Ω–Ω—è

–Ü–Ω—Å—Ç—Ä—É–∫—Ü—ñ—è –¥–ª—è —Ä–æ–∑—Ä–æ–±–Ω–∏–∫—ñ–≤, —è–∫—ñ —Ö–æ—á—É—Ç—å —Ä–æ–∑—à–∏—Ä–∏—Ç–∏ Codemap Analyzer.

## üèóÔ∏è –ê—Ä—Ö—ñ—Ç–µ–∫—Ç—É—Ä–∞

### –û—Å–Ω–æ–≤–Ω–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä–∞

```python
class CodeAnalyzer:
    def __init__(self, config_path: str)
    def analyze_project(self) -> Dict
    def generate_reports(self, summary: Dict)
    def watch_and_update(self)
```

### –ú–µ—Ç–æ–¥–∏ –∞–Ω–∞–ª—ñ–∑—É

```python
def _collect_files(self) -> List[Path]
def _analyze_file(self, file_path: Path)
def _analyze_python_file(self, file_path: Path, content: str)
def _analyze_javascript_file(self, file_path: Path, content: str)
def _detect_dead_code(self)
def _detect_cycles(self) -> List[List[str]]
def _calculate_complexity(self) -> Dict
```

### –ú–µ—Ç–æ–¥–∏ –≥–µ–Ω–µ—Ä–∞—Ü—ñ—ó –∑–≤—ñ—Ç—ñ–≤

```python
def _generate_json_report(self, summary: Dict)
def _generate_markdown_report(self, summary: Dict)
def _generate_html_report(self, summary: Dict)
```

## üîß –î–æ–¥–∞–≤–∞–Ω–Ω—è –Ω–æ–≤–æ—ó –º–æ–≤–∏

### –ö—Ä–æ–∫ 1: –î–æ–¥–∞–π —Ä–æ–∑—à–∏—Ä–µ–Ω–Ω—è –≤ config.yaml

```yaml
file_extensions:
  - ".py"
  - ".js"
  - ".ts"
  - ".go"  # ‚Üê –ù–æ–≤–∞ –º–æ–≤–∞
```

### –ö—Ä–æ–∫ 2: –î–æ–¥–∞–π –º–µ—Ç–æ–¥ –∞–Ω–∞–ª—ñ–∑—É –≤ codemap_analyzer.py

```python
def _analyze_file(self, file_path: Path):
    """Analyze a single file for imports, functions, and calls"""
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()
        
        if file_path.suffix == ".py":
            self._analyze_python_file(file_path, content)
        elif file_path.suffix in [".js", ".ts", ".tsx", ".jsx"]:
            self._analyze_javascript_file(file_path, content)
        elif file_path.suffix == ".go":  # ‚Üê –ù–æ–≤–∞ –º–æ–≤–∞
            self._analyze_go_file(file_path, content)
    
    except Exception as e:
        print(f"‚ö†Ô∏è  Error analyzing {file_path}: {e}")

def _analyze_go_file(self, file_path: Path, content: str):
    """Analyze Go file"""
    import re
    
    rel_path = str(file_path.relative_to(self.project_root))
    
    # Find imports
    import_pattern = r'import\s+(?:\(\s*)?["\']([^"\']+)["\']'
    for match in re.finditer(import_pattern, content):
        module = match.group(1)
        self.file_imports[rel_path].add(module)
        self.dependency_graph.add_edge(rel_path, module)
    
    # Find function definitions
    func_pattern = r'func\s+(?:\([^)]*\)\s+)?(\w+)\s*\('
    for match in re.finditer(func_pattern, content):
        func_name = match.group(1)
        self.function_definitions[rel_path][func_name] = {
            "lineno": content[:match.start()].count('\n') + 1,
            "is_private": func_name[0].islower()
        }
    
    # Find function calls
    call_pattern = r'(\w+)\s*\('
    for match in re.finditer(call_pattern, content):
        self.function_calls[rel_path].add(match.group(1))
```

### –ö—Ä–æ–∫ 3: –¢–µ—Å—Ç—É–≤–∞–Ω–Ω—è

```bash
# –î–æ–¥–∞–π Go —Ñ–∞–π–ª –≤ –ø—Ä–∏–∫–ª–∞–¥
cat > example_project/main.go << 'EOF'
package main

import "fmt"

func main() {
    fmt.Println("Hello")
}

func unused() {
    fmt.Println("Not used")
}
EOF

# –ó–∞–ø—É—Å—Ç–∏ –∞–Ω–∞–ª—ñ–∑–∞—Ç–æ—Ä
python3 codemap_analyzer.py --once

# –ü–µ—Ä–µ–≤—ñ—Ä —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏
cat reports/CODEMAP_SUMMARY.md
```

## üìä –î–æ–¥–∞–≤–∞–Ω–Ω—è –Ω–æ–≤–æ–≥–æ —Ñ–æ—Ä–º–∞—Ç—É –∑–≤—ñ—Ç—É

### –ö—Ä–æ–∫ 1: –î–æ–¥–∞–π —Ñ–æ—Ä–º–∞—Ç –≤ config.yaml

```yaml
output:
  formats:
    - "json"
    - "html"
    - "markdown"
    - "csv"  # ‚Üê –ù–æ–≤–∏–π —Ñ–æ—Ä–º–∞—Ç
```

### –ö—Ä–æ–∫ 2: –î–æ–¥–∞–π –º–µ—Ç–æ–¥ –≥–µ–Ω–µ—Ä–∞—Ü—ñ—ó

```python
def _generate_csv_report(self, summary: Dict[str, Any]):
    """Generate CSV report"""
    import csv
    
    report_path = self.reports_dir / "codemap_analysis.csv"
    
    with open(report_path, 'w', newline='') as f:
        writer = csv.writer(f)
        
        # Header
        writer.writerow(['Type', 'File', 'Name', 'Line'])
        
        # Dead code
        for item in summary['dead_code']['functions']:
            writer.writerow(['Unused Function', item['file'], item['name'], item['line']])
        
        for item in summary['dead_code']['private_methods']:
            writer.writerow(['Unused Private Method', item['file'], item['name'], item['line']])
```

### –ö—Ä–æ–∫ 3: –î–æ–¥–∞–π –≤ generate_reports()

```python
def generate_reports(self, summary: Dict[str, Any]):
    """Generate reports in multiple formats"""
    formats = self.config.get("output", {}).get("formats", ["json", "markdown"])
    
    if "json" in formats:
        self._generate_json_report(summary)
    
    if "markdown" in formats:
        self._generate_markdown_report(summary)
    
    if "html" in formats:
        self._generate_html_report(summary)
    
    if "csv" in formats:  # ‚Üê –ù–æ–≤–∏–π —Ñ–æ—Ä–º–∞—Ç
        self._generate_csv_report(summary)
```

## üîç –î–æ–¥–∞–≤–∞–Ω–Ω—è –Ω–æ–≤–æ–≥–æ –ø—Ä–∞–≤–∏–ª–∞ –¥–ª—è –º–µ—Ä—Ç–≤–æ–≥–æ –∫–æ–¥—É

### –ö—Ä–æ–∫ 1: –î–æ–¥–∞–π –ø—Ä–∞–≤–∏–ª–æ –≤ config.yaml

```yaml
dead_code_rules:
  unused_functions: true
  unused_variables: true
  unused_imports: true
  unused_private_methods: true
  unused_constants: true  # ‚Üê –ù–æ–≤–µ –ø—Ä–∞–≤–∏–ª–æ
```

### –ö—Ä–æ–∫ 2: –†–µ–∞–ª—ñ–∑—É–π –ª–æ–≥—ñ–∫—É

```python
def _detect_dead_code(self):
    """Detect unused functions, variables, and imports"""
    rules = self.config.get("dead_code_rules", {})
    
    # ... —ñ—Å–Ω—É—é—á–∏–π –∫–æ–¥ ...
    
    if rules.get("unused_constants"):
        # –ó–Ω–∞–π—Ç–∏ –∫–æ–Ω—Å—Ç–∞–Ω—Ç–∏ (UPPERCASE_NAME)
        for file_path, functions in self.function_definitions.items():
            # –õ–æ–≥—ñ–∫–∞ –¥–ª—è –∫–æ–Ω—Å—Ç–∞–Ω—Ç
            pass
```

## üß™ –¢–µ—Å—Ç—É–≤–∞–Ω–Ω—è

### –ó–∞–ø—É—Å–∫ —Ç–µ—Å—Ç—ñ–≤

```bash
# –¢–µ—Å—Ç—É–≤–∞–Ω–Ω—è –Ω–∞ –ø—Ä–∏–∫–ª–∞–¥—ñ
python3 codemap_analyzer.py --once

# –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ –∑–≤—ñ—Ç—ñ–≤
ls reports/
cat reports/CODEMAP_SUMMARY.md
cat reports/codemap_analysis.json | jq
```

### –ù–∞–ø–∏—Å–∞–Ω–Ω—è —Ç–µ—Å—Ç—ñ–≤

```python
# test_codemap.py
import unittest
from codemap_analyzer import CodeAnalyzer

class TestCodeAnalyzer(unittest.TestCase):
    def setUp(self):
        self.analyzer = CodeAnalyzer("config.yaml")
    
    def test_collect_files(self):
        files = self.analyzer._collect_files()
        self.assertGreater(len(files), 0)
    
    def test_analyze_project(self):
        summary = self.analyzer.analyze_project()
        self.assertIn("files_analyzed", summary)
        self.assertIn("total_functions", summary)
    
    def test_detect_cycles(self):
        self.analyzer.analyze_project()
        cycles = self.analyzer._detect_cycles()
        self.assertIsInstance(cycles, list)

if __name__ == '__main__':
    unittest.main()
```

–ó–∞–ø—É—Å–∫ —Ç–µ—Å—Ç—ñ–≤:

```bash
python3 -m unittest test_codemap.py
```

## üìù –î–æ–¥–∞–≤–∞–Ω–Ω—è –Ω–æ–≤–æ–≥–æ workflow

### –ö—Ä–æ–∫ 1: –°—Ç–≤–æ—Ä–∏ —Ñ–∞–π–ª

```bash
cat > .windsurf/workflows/my-custom-workflow.md << 'EOF'
# My Custom Workflow

Description

## –ö—Ä–æ–∫–∏

1. –ó–∞–ø—É—Å—Ç–∏ –∞–Ω–∞–ª—ñ–∑
   ```bash
   python3 codemap_analyzer.py --once
   ```

2. –ü—Ä–æ—á–∏—Ç–∞–π –∑–≤—ñ—Ç
   @reports/CODEMAP_SUMMARY.md

3. –¢–≤–æ—è –ª–æ–≥—ñ–∫–∞
   ...
EOF
```

### –ö—Ä–æ–∫ 2: –¢–µ—Å—Ç—É–≤–∞–Ω–Ω—è

```
Ctrl+L ‚Üí /my-custom-workflow
```

## üöÄ –û–ø—Ç–∏–º—ñ–∑–∞—Ü—ñ—è

### –ü–∞—Ä–∞–ª–µ–ª—ñ–∑–∞—Ü—ñ—è –∞–Ω–∞–ª—ñ–∑—É

```python
from concurrent.futures import ThreadPoolExecutor

def analyze_project(self) -> Dict[str, Any]:
    """Run full project analysis with parallelization"""
    files = self._collect_files()
    
    # –ü–∞—Ä–∞–ª–µ–ª—å–Ω–∏–π –∞–Ω–∞–ª—ñ–∑
    with ThreadPoolExecutor(max_workers=4) as executor:
        executor.map(self._analyze_file, files)
    
    # ... —Ä–µ—à—Ç–∞ –∫–æ–¥—É ...
```

### –ö–µ—à—É–≤–∞–Ω–Ω—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤

```python
def _analyze_file(self, file_path: Path):
    """Analyze a single file with caching"""
    file_hash = self._get_file_hash(file_path)
    
    # –ü–µ—Ä–µ–≤—ñ—Ä –∫–µ—à
    if file_path in self.file_hashes and self.file_hashes[file_path] == file_hash:
        return  # –§–∞–π–ª –Ω–µ –∑–º—ñ–Ω–∏–≤—Å—è
    
    # –ê–Ω–∞–ª—ñ–∑
    # ... –∫–æ–¥ ...
    
    # –ó–±–µ—Ä–µ–∂–∏ —Ö–µ—à
    self.file_hashes[str(file_path)] = file_hash

def _get_file_hash(self, file_path: Path) -> str:
    """Get file hash for change detection"""
    import hashlib
    with open(file_path, 'rb') as f:
        return hashlib.md5(f.read()).hexdigest()
```

## üìö –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü—ñ—è –∫–æ–¥—É

### Docstrings

```python
def analyze_project(self) -> Dict[str, Any]:
    """
    Run full project analysis.
    
    Analyzes all files in the project, detects dependencies,
    dead code, and circular dependencies.
    
    Returns:
        Dict with analysis results including:
        - files_analyzed: number of files
        - total_functions: total functions found
        - dependency_graph: graph statistics
        - dead_code: unused code
        - cycles: circular dependencies
    """
    pass
```

### Type hints

```python
def _collect_files(self) -> List[Path]:
    """Collect all files to analyze based on config"""
    pass

def _analyze_file(self, file_path: Path) -> None:
    """Analyze a single file for imports, functions, and calls"""
    pass

def _detect_cycles(self) -> List[List[str]]:
    """Detect circular dependencies"""
    pass
```

## üîÑ Git Workflow

### –ì—ñ–ª–∫–∏

```bash
# –û—Å–Ω–æ–≤–Ω–∞ –≥—ñ–ª–∫–∞
git checkout main

# –°—Ç–≤–æ—Ä–∏ –≥—ñ–ª–∫—É –¥–ª—è –Ω–æ–≤–æ—ó —Ñ—É–Ω–∫—Ü—ñ—ó
git checkout -b feature/add-go-support

# –†–æ–∑—Ä–æ–±–∫–∞
# ...

# –ö–æ–º—ñ—Ç
git add .
git commit -m "Add Go language support"

# Push
git push origin feature/add-go-support

# Pull Request –Ω–∞ GitHub
```

### –ö–æ–º—ñ—Ç–∏

```bash
# –•–æ—Ä–æ—à–∏–π –∫–æ–º—ñ—Ç
git commit -m "Add Go language support

- Implement _analyze_go_file() method
- Add .go extension to config
- Update documentation"

# –ü–æ–≥–∞–Ω–∏–π –∫–æ–º—ñ—Ç
git commit -m "fix"
```

## üìã –ß–µ–∫-–ª–∏—Å—Ç –¥–ª—è –Ω–æ–≤–æ—ó —Ñ—É–Ω–∫—Ü—ñ—ó

- [ ] –ö–æ–¥ –Ω–∞–ø–∏—Å–∞–Ω–∏–π
- [ ] –¢–µ—Å—Ç–∏ –Ω–∞–ø–∏—Å–∞–Ω—ñ
- [ ] –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü—ñ—è –æ–Ω–æ–≤–ª–µ–Ω–∞
- [ ] –ü—Ä–∏–∫–ª–∞–¥–∏ –¥–æ–¥–∞–Ω—ñ
- [ ] –ö–æ–º—ñ—Ç–∏ —á–∏—Å—Ç—ñ
- [ ] Pull Request —Å—Ç–≤–æ—Ä–µ–Ω–∏–π
- [ ] Code review –ø—Ä–æ–π–¥–µ–Ω–∏–π
- [ ] Merged –≤ main

## üéØ –ù–∞–ø—Ä—è–º–∫–∏ —Ä–æ–∑–≤–∏—Ç–∫—É

### –ö–æ—Ä–æ—Ç–∫–æ—Å—Ç—Ä–æ–∫–æ–≤—ñ

- [ ] –î–æ–¥–∞—Ç–∏ Go, Java, C#
- [ ] –ü–∞—Ä–∞–ª–µ–ª—ñ–∑–∞—Ü—ñ—è –∞–Ω–∞–ª—ñ–∑—É
- [ ] –ö–µ—à—É–≤–∞–Ω–Ω—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤
- [ ] –ë—ñ–ª—å—à–µ —Ñ–æ—Ä–º–∞—Ç—ñ–≤ –∑–≤—ñ—Ç—ñ–≤ (CSV, XML)

### –°–µ—Ä–µ–¥–Ω—å–æ—Å—Ç—Ä–æ–∫–æ–≤—ñ

- [ ] Web UI –¥–ª—è –∑–≤—ñ—Ç—ñ–≤
- [ ] REST API
- [ ] MCP Tool –¥–ª—è Windsurf
- [ ] –Ü–Ω—Ç–µ–≥—Ä–∞—Ü—ñ—è –∑ SonarQube

### –î–æ–≤–≥–æ—Å—Ç—Ä–æ–∫–æ–≤—ñ

- [ ] Machine Learning –¥–ª—è –≤–∏—è–≤–ª–µ–Ω–Ω—è –ø–∞—Ç—Ç–µ—Ä–Ω—ñ–≤
- [ ] –ü–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è –∑–≤—ñ—Ç—ñ–≤ (diff)
- [ ] –¢—Ä–µ–Ω–¥–∏ (–≥—Ä–∞—Ñ—ñ–∫–∏ –∑–º—ñ–Ω)
- [ ] –•–º–∞—Ä–Ω–∞ —Å–∏–Ω—Ö—Ä–æ–Ω—ñ–∑–∞—Ü—ñ—è

## üìû –ö–æ–Ω—Ç–∞–∫—Ç–∏

–Ø–∫—â–æ —É —Ç–µ–±–µ —î –ø–∏—Ç–∞–Ω–Ω—è:

1. –ü–µ—Ä–µ–≤—ñ—Ä [ARCHITECTURE.md](ARCHITECTURE.md)
2. –ü–µ—Ä–µ–≤—ñ—Ä [FAQ.md](FAQ.md)
3. –ó–∞–ø—É—Å—Ç–∏ –ø—Ä–∏–∫–ª–∞–¥
4. –í—ñ–¥–∫—Ä–∏–π issue –Ω–∞ GitHub

---

**–î—è–∫—É—î–º–æ –∑–∞ —Ä–æ–∑—Ä–æ–±–∫—É! üöÄ**
