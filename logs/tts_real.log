2025-10-26 17:43:23,202 [ukrainian-tts-server] INFO: Python executable: /Users/dev/Documents/GitHub/atlas4/web/venv/bin/python3
2025-10-26 17:43:23,203 [ukrainian-tts-server] INFO: VIRTUAL_ENV/CONDA_PREFIX: /Users/dev/Documents/GitHub/atlas4/web/venv
2025-10-26 17:43:23,203 [ukrainian-tts-server] INFO: sys.path (first entries): ['/Users/dev/Documents/GitHub/atlas4/ukrainian-tts', '/Users/dev/.pyenv/versions/3.11.13/lib/python311.zip', '/Users/dev/.pyenv/versions/3.11.13/lib/python3.11', '/Users/dev/.pyenv/versions/3.11.13/lib/python3.11/lib-dynload', '/Users/dev/Documents/GitHub/atlas4/web/venv/lib/python3.11/site-packages']
2025-10-26 17:43:23,203 [ukrainian-tts-server] INFO: Initializing Ukrainian TTS on device: mps
/Users/dev/Documents/GitHub/atlas4/web/venv/lib/python3.11/site-packages/pyworld/__init__.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
  import pkg_resources
/Users/dev/Documents/GitHub/atlas4/web/venv/lib/python3.11/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  return self.fget.__get__(instance, owner)()
2025-10-26 17:43:26,570 [stanza] INFO: Loading these models for language: uk (Ukrainian):
=========================
| Processor | Package   |
-------------------------
| tokenize  | iu        |
| mwt       | iu        |
| pos       | iu_charlm |
=========================

2025-10-26 17:43:26,570 [stanza] INFO: Using device: cpu
2025-10-26 17:43:26,570 [stanza] INFO: Loading: tokenize
2025-10-26 17:43:26,742 [stanza] INFO: Loading: mwt
2025-10-26 17:43:26,745 [stanza] INFO: Loading: pos
2025-10-26 17:43:27,678 [stanza] INFO: Done loading processors!
2025-10-26 17:43:27,724 [root] INFO: Vocabulary size: 48
/Users/dev/Documents/GitHub/atlas4/web/venv/lib/python3.11/site-packages/torch/nn/utils/weight_norm.py:30: UserWarning: torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.
  warnings.warn("torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.")
2025-10-26 17:43:28,577 [root] INFO: Extractor:
LogMelFbank(
  (stft): Stft(n_fft=1024, win_length=1024, hop_length=256, center=True, normalized=False, onesided=True)
  (logmel): LogMel(sr=22050, n_fft=1024, n_mels=80, fmin=80, fmax=7600, htk=False)
)
2025-10-26 17:43:28,577 [root] INFO: Normalizer:
GlobalMVN(stats_file=feats_stats.npz, norm_means=True, norm_vars=True)
2025-10-26 17:43:28,578 [root] INFO: TTS:
JointText2Wav(
  (generator): ModuleDict(
    (text2mel): Tacotron2(
      (enc): Encoder(
        (embed): Embedding(48, 512, padding_idx=0)
        (convs): ModuleList(
          (0-2): 3 x Sequential(
            (0): Conv1d(512, 512, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)
            (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Dropout(p=0.5, inplace=False)
          )
        )
        (blstm): LSTM(512, 256, batch_first=True, bidirectional=True)
      )
      (projection): Linear(in_features=192, out_features=512, bias=True)
      (dec): Decoder(
        (att): AttLoc(
          (mlp_enc): Linear(in_features=512, out_features=512, bias=True)
          (mlp_dec): Linear(in_features=1024, out_features=512, bias=False)
          (mlp_att): Linear(in_features=32, out_features=512, bias=False)
          (loc_conv): Conv2d(1, 32, kernel_size=(1, 31), stride=(1, 1), padding=(0, 15), bias=False)
          (gvec): Linear(in_features=512, out_features=1, bias=True)
        )
        (lstm): ModuleList(
          (0): ZoneOutCell(
            (cell): LSTMCell(768, 1024)
          )
          (1): ZoneOutCell(
            (cell): LSTMCell(1024, 1024)
          )
        )
        (prenet): Prenet(
          (prenet): ModuleList(
            (0): Sequential(
              (0): Linear(in_features=80, out_features=256, bias=True)
              (1): ReLU()
            )
            (1): Sequential(
              (0): Linear(in_features=256, out_features=256, bias=True)
              (1): ReLU()
            )
          )
        )
        (postnet): Postnet(
          (postnet): ModuleList(
            (0): Sequential(
              (0): Conv1d(80, 512, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)
              (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Tanh()
              (3): Dropout(p=0.5, inplace=False)
            )
            (1-3): 3 x Sequential(
              (0): Conv1d(512, 512, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)
              (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Tanh()
              (3): Dropout(p=0.5, inplace=False)
            )
            (4): Sequential(
              (0): Conv1d(512, 80, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)
              (1): BatchNorm1d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Dropout(p=0.5, inplace=False)
            )
          )
        )
        (feat_out): Linear(in_features=1536, out_features=80, bias=False)
        (prob_out): Linear(in_features=1536, out_features=1, bias=True)
      )
      (taco2_loss): Tacotron2Loss(
        (l1_criterion): L1Loss()
        (mse_criterion): MSELoss()
        (bce_criterion): BCEWithLogitsLoss()
      )
      (attn_loss): GuidedAttentionLoss()
    )
    (vocoder): HiFiGANGenerator(
      (input_conv): Conv1d(80, 512, kernel_size=(7,), stride=(1,), padding=(3,))
      (upsamples): ModuleList(
        (0): Sequential(
          (0): LeakyReLU(negative_slope=0.1)
          (1): ConvTranspose1d(512, 256, kernel_size=(16,), stride=(8,), padding=(4,))
        )
        (1): Sequential(
          (0): LeakyReLU(negative_slope=0.1)
          (1): ConvTranspose1d(256, 128, kernel_size=(16,), stride=(8,), padding=(4,))
        )
        (2): Sequential(
          (0): LeakyReLU(negative_slope=0.1)
          (1): ConvTranspose1d(128, 64, kernel_size=(4,), stride=(2,), padding=(1,))
        )
        (3): Sequential(
          (0): LeakyReLU(negative_slope=0.1)
          (1): ConvTranspose1d(64, 32, kernel_size=(4,), stride=(2,), padding=(1,))
        )
      )
      (blocks): ModuleList(
        (0): ResidualBlock(
          (convs1): ModuleList(
            (0): Sequential(
              (0): LeakyReLU(negative_slope=0.1)
              (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))
            )
            (1): Sequential(
              (0): LeakyReLU(negative_slope=0.1)
              (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
            )
            (2): Sequential(
              (0): LeakyReLU(negative_slope=0.1)
              (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))
            )
          )
          (convs2): ModuleList(
            (0-2): 3 x Sequential(
              (0): LeakyReLU(negative_slope=0.1)
              (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))
            )
          )
        )
        (1): ResidualBlock(
          (convs1): ModuleList(
            (0): Sequential(
              (0): LeakyReLU(negative_slope=0.1)
              (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,))
            )
            (1): Sequential(
              (0): LeakyReLU(negative_slope=0.1)
              (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))
            )
            (2): Sequential(
              (0): LeakyReLU(negative_slope=0.1)
              (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))
            )
          )
          (convs2): ModuleList(
            (0-2): 3 x Sequential(
              (0): LeakyReLU(negative_slope=0.1)
              (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,))
            )
          )
        )
        (2): ResidualBlock(
          (convs1): ModuleList(
            (0): Sequential(
              (0): LeakyReLU(negative_slope=0.1)
              (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(5,))
            )
            (1): Sequential(
              (0): LeakyReLU(negative_slope=0.1)
              (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))
            )
            (2): Sequential(
              (0): LeakyReLU(negative_slope=0.1)
              (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))
            )
          )
          (convs2): ModuleList(
            (0-2): 3 x Sequential(
              (0): LeakyReLU(negative_slope=0.1)
              (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(5,))
            )
          )
        )
        (3): ResidualBlock(
          (convs1): ModuleList(
            (0): Sequential(
              (0): LeakyReLU(negative_slope=0.1)
              (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))
            )
            (1): Sequential(
              (0): LeakyReLU(negative_slope=0.1)
              (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
            )
            (2): Sequential(
              (0): LeakyReLU(negative_slope=0.1)
              (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))
            )
          )
          (convs2): ModuleList(
            (0-2): 3 x Sequential(
              (0): LeakyReLU(negative_slope=0.1)
              (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))
            )
          )
        )
        (4): ResidualBlock(
          (convs1): ModuleList(
            (0): Sequential(
              (0): LeakyReLU(negative_slope=0.1)
              (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,))
            )
            (1): Sequential(
              (0): LeakyReLU(negative_slope=0.1)
              (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))
            )
            (2): Sequential(
              (0): LeakyReLU(negative_slope=0.1)
              (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))
            )
          )
          (convs2): ModuleList(
            (0-2): 3 x Sequential(
              (0): LeakyReLU(negative_slope=0.1)
              (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,))
            )
          )
        )
        (5): ResidualBlock(
          (convs1): ModuleList(
            (0): Sequential(
              (0): LeakyReLU(negative_slope=0.1)
              (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(5,))
            )
            (1): Sequential(
              (0): LeakyReLU(negative_slope=0.1)
              (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))
            )
            (2): Sequential(
              (0): LeakyReLU(negative_slope=0.1)
              (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))
            )
          )
          (convs2): ModuleList(
            (0-2): 3 x Sequential(
              (0): LeakyReLU(negative_slope=0.1)
              (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(5,))
            )
          )
        )
        (6): ResidualBlock(
          (convs1): ModuleList(
            (0): Sequential(
              (0): LeakyReLU(negative_slope=0.1)
              (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))
            )
            (1): Sequential(
              (0): LeakyReLU(negative_slope=0.1)
              (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
            )
            (2): Sequential(
              (0): LeakyReLU(negative_slope=0.1)
              (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))
            )
          )
          (convs2): ModuleList(
            (0-2): 3 x Sequential(
              (0): LeakyReLU(negative_slope=0.1)
              (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))
            )
          )
        )
        (7): ResidualBlock(
          (convs1): ModuleList(
            (0): Sequential(
              (0): LeakyReLU(negative_slope=0.1)
              (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(3,))
            )
            (1): Sequential(
              (0): LeakyReLU(negative_slope=0.1)
              (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))
            )
            (2): Sequential(
              (0): LeakyReLU(negative_slope=0.1)
              (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))
            )
          )
          (convs2): ModuleList(
            (0-2): 3 x Sequential(
              (0): LeakyReLU(negative_slope=0.1)
              (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(3,))
            )
          )
        )
        (8): ResidualBlock(
          (convs1): ModuleList(
            (0): Sequential(
              (0): LeakyReLU(negative_slope=0.1)
              (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(5,))
            )
            (1): Sequential(
              (0): LeakyReLU(negative_slope=0.1)
              (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))
            )
            (2): Sequential(
              (0): LeakyReLU(negative_slope=0.1)
              (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))
            )
          )
          (convs2): ModuleList(
            (0-2): 3 x Sequential(
              (0): LeakyReLU(negative_slope=0.1)
              (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(5,))
            )
          )
        )
        (9): ResidualBlock(
          (convs1): ModuleList(
            (0): Sequential(
              (0): LeakyReLU(negative_slope=0.1)
              (1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))
            )
            (1): Sequential(
              (0): LeakyReLU(negative_slope=0.1)
              (1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
            )
            (2): Sequential(
              (0): LeakyReLU(negative_slope=0.1)
              (1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))
            )
          )
          (convs2): ModuleList(
            (0-2): 3 x Sequential(
              (0): LeakyReLU(negative_slope=0.1)
              (1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))
            )
          )
        )
        (10): ResidualBlock(
          (convs1): ModuleList(
            (0): Sequential(
              (0): LeakyReLU(negative_slope=0.1)
              (1): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(3,))
            )
            (1): Sequential(
              (0): LeakyReLU(negative_slope=0.1)
              (1): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))
            )
            (2): Sequential(
              (0): LeakyReLU(negative_slope=0.1)
              (1): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))
            )
          )
          (convs2): ModuleList(
            (0-2): 3 x Sequential(
              (0): LeakyReLU(negative_slope=0.1)
              (1): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(3,))
            )
          )
        )
        (11): ResidualBlock(
          (convs1): ModuleList(
            (0): Sequential(
              (0): LeakyReLU(negative_slope=0.1)
              (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(5,))
            )
            (1): Sequential(
              (0): LeakyReLU(negative_slope=0.1)
              (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))
            )
            (2): Sequential(
              (0): LeakyReLU(negative_slope=0.1)
              (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))
            )
          )
          (convs2): ModuleList(
            (0-2): 3 x Sequential(
              (0): LeakyReLU(negative_slope=0.1)
              (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(5,))
            )
          )
        )
      )
      (output_conv): Sequential(
        (0): LeakyReLU(negative_slope=0.01)
        (1): Conv1d(32, 1, kernel_size=(7,), stride=(1,), padding=(3,))
        (2): Tanh()
      )
    )
  )
  (discriminator): HiFiGANMultiScaleMultiPeriodDiscriminator(
    (msd): HiFiGANMultiScaleDiscriminator(
      (discriminators): ModuleList(
        (0-2): 3 x HiFiGANScaleDiscriminator(
          (layers): ModuleList(
            (0): Sequential(
              (0): Conv1d(1, 128, kernel_size=(15,), stride=(1,), padding=(7,))
              (1): LeakyReLU(negative_slope=0.1)
            )
            (1): Sequential(
              (0): Conv1d(128, 128, kernel_size=(41,), stride=(4,), padding=(20,), groups=4)
              (1): LeakyReLU(negative_slope=0.1)
            )
            (2): Sequential(
              (0): Conv1d(128, 256, kernel_size=(41,), stride=(4,), padding=(20,), groups=16)
              (1): LeakyReLU(negative_slope=0.1)
            )
            (3): Sequential(
              (0): Conv1d(256, 512, kernel_size=(41,), stride=(4,), padding=(20,), groups=16)
              (1): LeakyReLU(negative_slope=0.1)
            )
            (4): Sequential(
              (0): Conv1d(512, 1024, kernel_size=(41,), stride=(4,), padding=(20,), groups=16)
              (1): LeakyReLU(negative_slope=0.1)
            )
            (5): Sequential(
              (0): Conv1d(1024, 1024, kernel_size=(41,), stride=(1,), padding=(20,), groups=16)
              (1): LeakyReLU(negative_slope=0.1)
            )
            (6): Sequential(
              (0): Conv1d(1024, 1024, kernel_size=(5,), stride=(1,), padding=(2,))
              (1): LeakyReLU(negative_slope=0.1)
            )
            (7): Conv1d(1024, 1, kernel_size=(3,), stride=(1,), padding=(1,))
          )
        )
      )
      (pooling): AvgPool1d(kernel_size=(4,), stride=(2,), padding=(2,))
    )
    (mpd): HiFiGANMultiPeriodDiscriminator(
      (discriminators): ModuleList(
        (0-4): 5 x HiFiGANPeriodDiscriminator(
          (convs): ModuleList(
            (0): Sequential(
              (0): Conv2d(1, 32, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))
              (1): LeakyReLU(negative_slope=0.1)
            )
            (1): Sequential(
              (0): Conv2d(32, 128, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))
              (1): LeakyReLU(negative_slope=0.1)
            )
            (2): Sequential(
              (0): Conv2d(128, 512, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))
              (1): LeakyReLU(negative_slope=0.1)
            )
            (3): Sequential(
              (0): Conv2d(512, 1024, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))
              (1): LeakyReLU(negative_slope=0.1)
            )
            (4): Sequential(
              (0): Conv2d(1024, 1024, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
              (1): LeakyReLU(negative_slope=0.1)
            )
          )
          (output_conv): Conv2d(1024, 1, kernel_size=(2, 1), stride=(1, 1), padding=(1, 0))
        )
      )
    )
  )
  (generator_adv_loss): GeneratorAdversarialLoss()
  (discriminator_adv_loss): DiscriminatorAdversarialLoss()
  (feat_match_loss): FeatureMatchLoss()
  (mel_loss): MelSpectrogramLoss(
    (wav_to_mel): LogMelFbank(
      (stft): Stft(n_fft=1024, win_length=1024, hop_length=256, center=True, normalized=False, onesided=True)
      (logmel): LogMel(sr=22050, n_fft=1024, n_mels=80, fmin=0, fmax=11025.0, htk=False)
    )
  )
)
2025-10-26 17:43:28,878 [ukrainian-tts-server] INFO: Ukrainian TTS initialized successfully
2025-10-26 17:43:28,879 [ukrainian-tts-server] INFO: Ukrainian TTS Server initialized at 127.0.0.1:3001
2025-10-26 17:43:28,879 [ukrainian-tts-server] INFO: Starting Ukrainian TTS Server on 127.0.0.1:3001
2025-10-26 17:43:28,879 [ukrainian-tts-server] INFO: TTS ready: True
2025-10-26 17:43:28,879 [ukrainian-tts-server] INFO: Device: mps
downloading https://github.com/robinhad/ukrainian-tts/releases/download/v6.0.0
Found ../model.pth. Skipping download...
Found ../config.yaml. Skipping download...
Found ../spk_xvector.ark. Skipping download...
Found ../feats_stats.npz. Skipping download...
downloaded.
 * Serving Flask app 'tts_server'
 * Debug mode: off
2025-10-26 17:43:28,893 [werkzeug] INFO: [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:3001
2025-10-26 17:43:28,893 [werkzeug] INFO: [33mPress CTRL+C to quit[0m
2025-10-26 17:43:32,626 [werkzeug] INFO: 127.0.0.1 - - [26/Oct/2025 17:43:32] "OPTIONS /health HTTP/1.1" 200 -
2025-10-26 17:43:32,627 [werkzeug] INFO: 127.0.0.1 - - [26/Oct/2025 17:43:32] "GET /health HTTP/1.1" 200 -
2025-10-26 17:44:00,578 [werkzeug] INFO: 127.0.0.1 - - [26/Oct/2025 17:44:00] "OPTIONS /tts HTTP/1.1" 200 -
2025-10-26 17:44:00,579 [ukrainian-tts-server] INFO: TTS request: text='Ð³Ð¾Ñ‚Ð¾Ð²Ð¸Ð¹ Ð´Ð¾ Ñ€Ð¾Ð±Ð¾Ñ‚Ð¸...', voice=mykyta, fx=none, length=17 chars
/Users/dev/Documents/GitHub/atlas4/web/venv/lib/python3.11/site-packages/espnet2/torch_utils/device_funcs.py:29: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:212.)
  return to_device(torch.from_numpy(data), device, dtype, non_blocking, copy)
/Users/dev/Documents/GitHub/atlas4/web/venv/lib/python3.11/site-packages/torch/nn/utils/weight_norm.py:26: UserWarning: The operator 'aten::_weight_norm_interface' is not currently supported on the MPS backend and will fall back to run on the CPU. This may have performance implications. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/mps/MPSFallback.mm:13.)
  return _weight_norm(v, g, self.dim)
2025-10-26 17:44:02,267 [werkzeug] INFO: 127.0.0.1 - - [26/Oct/2025 17:44:02] "POST /tts HTTP/1.1" 200 -
2025-10-26 17:44:28,864 [werkzeug] INFO: 127.0.0.1 - - [26/Oct/2025 17:44:28] "OPTIONS /tts HTTP/1.1" 200 -
2025-10-26 17:44:28,875 [ukrainian-tts-server] INFO: TTS request: text='ÐŸÑ€Ð¸Ð²Ñ–Ñ‚, ÐžÐ»ÐµÐ¶Ðµ ÐœÐ¸ÐºÐ¾Ð»Ð°Ð¹Ð¾Ð²Ð¸Ñ‡Ñƒ! Ð¯ Ð·Ð°Ð²Ð¶Ð´Ð¸ Ð³Ð¾Ñ‚Ð¾Ð²Ð¸Ð¹ Ð´Ð¾ Ñ€Ð¾...', voice=mykyta, fx=none, length=424 chars
2025-10-26 17:44:47,899 [werkzeug] INFO: 127.0.0.1 - - [26/Oct/2025 17:44:47] "POST /tts HTTP/1.1" 200 -
2025-10-26 17:45:00,897 [werkzeug] INFO: 127.0.0.1 - - [26/Oct/2025 17:45:00] "OPTIONS /tts HTTP/1.1" 200 -
2025-10-26 17:45:00,899 [ukrainian-tts-server] INFO: TTS request: text='Ñ‚Ð°Ðº Ñ‚Ð²Ð¾Ñ€ÐµÑ†ÑŒ, Ð²Ð¸ Ð¼ÐµÐ½Ðµ Ð·Ð²Ð°Ð»Ð¸...', voice=mykyta, fx=none, length=26 chars
2025-10-26 17:45:02,789 [werkzeug] INFO: 127.0.0.1 - - [26/Oct/2025 17:45:02] "POST /tts HTTP/1.1" 200 -
2025-10-26 17:45:25,040 [werkzeug] INFO: 127.0.0.1 - - [26/Oct/2025 17:45:25] "OPTIONS /tts HTTP/1.1" 200 -
2025-10-26 17:45:25,042 [ukrainian-tts-server] INFO: TTS request: text='Ð—Ð´Ñ€Ð°ÑÑ‚ÑƒÐ¹Ñ‚Ðµ, ÐžÐ»ÐµÐ³ ÐœÐ¸ÐºÐ¾Ð»Ð°Ð¹Ð¾Ð²Ð¸Ñ‡! Ð¯ â€” ÐÑ‚Ð»Ð°Ñ, Ð²Ð°Ñˆ Ð¿Ð°Ñ€Ñ‚Ð½...', voice=mykyta, fx=none, length=126 chars
2025-10-26 17:45:31,980 [werkzeug] INFO: 127.0.0.1 - - [26/Oct/2025 17:45:31] "POST /tts HTTP/1.1" 200 -
2025-10-26 17:45:43,456 [werkzeug] INFO: 127.0.0.1 - - [26/Oct/2025 17:45:43] "OPTIONS /tts HTTP/1.1" 200 -
2025-10-26 17:45:43,457 [ukrainian-tts-server] INFO: TTS request: text='Ð¯ â€” ÐÑ‚Ð»Ð°Ñ, Ñ‚Ð²Ð¾Ñ” Ñ†Ð¸Ñ„Ñ€Ð¾Ð²Ðµ ÑÑ‚Ð²Ð¾Ñ€Ñ–Ð½Ð½Ñ, Ð³Ð¾Ñ‚Ð¾Ð²Ð¸Ð¹ Ð´Ð¾ Ð½Ð¾Ð²Ð¸...', voice=mykyta, fx=none, length=104 chars
2025-10-26 17:45:49,040 [werkzeug] INFO: 127.0.0.1 - - [26/Oct/2025 17:45:49] "POST /tts HTTP/1.1" 200 -
2025-10-26 17:45:58,273 [werkzeug] INFO: 127.0.0.1 - - [26/Oct/2025 17:45:58] "OPTIONS /tts HTTP/1.1" 200 -
2025-10-26 17:45:58,275 [ukrainian-tts-server] INFO: TTS request: text='Ð—Ð´Ñ€Ð°ÑÑ‚ÑƒÐ¹Ñ‚Ðµ, ÐžÐ»ÐµÐ³ ÐœÐ¸ÐºÐ¾Ð»Ð°Ð¹Ð¾Ð²Ð¸Ñ‡! Ð¯ â€” ÐÑ‚Ð»Ð°Ñ, Ð²Ð°Ñˆ Ð¿Ð°Ñ€Ñ‚Ð½...', voice=mykyta, fx=none, length=98 chars
2025-10-26 17:46:03,556 [werkzeug] INFO: 127.0.0.1 - - [26/Oct/2025 17:46:03] "POST /tts HTTP/1.1" 200 -
2025-10-26 17:46:12,949 [werkzeug] INFO: 127.0.0.1 - - [26/Oct/2025 17:46:12] "OPTIONS /tts HTTP/1.1" 200 -
2025-10-26 17:46:12,951 [ukrainian-tts-server] INFO: TTS request: text='Ð”Ð¾Ð±Ñ€Ð¾Ð³Ð¾ Ð´Ð½Ñ, ÐžÐ»ÐµÐ¶Ðµ ÐœÐ¸ÐºÐ¾Ð»Ð°Ð¹Ð¾Ð²Ð¸Ñ‡Ñƒ! Ð¯ â€” ÐÑ‚Ð»Ð°Ñ, Ð²Ð°ÑˆÐµ Ñ‚...', voice=mykyta, fx=none, length=138 chars
2025-10-26 17:46:20,110 [werkzeug] INFO: 127.0.0.1 - - [26/Oct/2025 17:46:20] "POST /tts HTTP/1.1" 200 -
2025-10-26 17:46:49,779 [werkzeug] INFO: 127.0.0.1 - - [26/Oct/2025 17:46:49] "OPTIONS /health HTTP/1.1" 200 -
2025-10-26 17:46:49,781 [werkzeug] INFO: 127.0.0.1 - - [26/Oct/2025 17:46:49] "GET /health HTTP/1.1" 200 -
