#!/usr/bin/env python3
"""
Performance Analyzer - –ê–Ω–∞–ª—ñ–∑ –ø—Ä–æ–¥—É–∫—Ç–∏–≤–Ω–æ—Å—Ç—ñ –∫–æ–¥—É
"""

import re
from pathlib import Path
from typing import Dict, List, Any, Optional
import sys

sys.path.insert(0, str(Path(__file__).parent.parent))


class PerformanceIssue:
    """–ü—Ä–æ–±–ª–µ–º–∞ –ø—Ä–æ–¥—É–∫—Ç–∏–≤–Ω–æ—Å—Ç—ñ"""
    
    def __init__(self, severity: str, issue_type: str, message: str, line: int = 0):
        self.severity = severity  # critical, high, medium, low
        self.issue_type = issue_type
        self.message = message
        self.line = line
    
    def to_dict(self) -> Dict[str, Any]:
        return {
            "severity": self.severity,
            "type": self.issue_type,
            "message": self.message,
            "line": self.line
        }


class PerformanceAnalyzer:
    """–ê–Ω–∞–ª—ñ–∑–∞—Ç–æ—Ä –ø—Ä–æ–¥—É–∫—Ç–∏–≤–Ω–æ—Å—Ç—ñ –∫–æ–¥—É"""
    
    def __init__(self, project_root: Optional[Path] = None):
        self.project_root = project_root or Path('.')
        
        # –ü–∞—Ç—Ç–µ—Ä–Ω–∏ –ø—Ä–æ–±–ª–µ–º –ø—Ä–æ–¥—É–∫—Ç–∏–≤–Ω–æ—Å—Ç—ñ
        self.performance_patterns = {
            # N+1 Queries
            r'for\s+\w+\s+in\s+.*:\s*.*query|for\s+\w+\s+in\s+.*:\s*.*select': 
                ('high', 'n_plus_one', '–ú–æ–∂–ª–∏–≤–∏–π N+1 query problem'),
            
            # Inefficient Loops
            r'for\s+\w+\s+in\s+range\(len\(': 
                ('medium', 'inefficient_loop', '–í–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è range(len()) –∑–∞–º—ñ—Å—Ç—å –ø—Ä—è–º–æ—ó —ñ—Ç–µ—Ä–∞—Ü—ñ—ó'),
            
            # Large Data Structures
            r'\.append\(|\.extend\(.*\)' in 'loop':
                ('medium', 'large_data_structure', '–ú–æ–∂–ª–∏–≤–µ —Å—Ç–≤–æ—Ä–µ–Ω–Ω—è –≤–µ–ª–∏–∫–æ—ó —Å—Ç—Ä—É–∫—Ç—É—Ä–∏ –¥–∞–Ω–∏—Ö'),
            
            # Synchronous Operations
            r'requests\.get|requests\.post|urllib\.request': 
                ('high', 'sync_io', '–°–∏–Ω—Ö—Ä–æ–Ω–Ω—ñ I/O –æ–ø–µ—Ä–∞—Ü—ñ—ó –±–ª–æ–∫—É—é—Ç—å –ø–æ—Ç—ñ–∫'),
            
            # Regex Compilation
            r're\.search\(|re\.match\(|re\.findall\(': 
                ('medium', 'regex_compilation', 'Regex –∫–æ–º–ø—ñ–ª—é—î—Ç—å—Å—è –∫–æ–∂–Ω–æ–≥–æ —Ä–∞–∑—É'),
            
            # Inefficient String Operations
            r'str\s*\+\s*str|".*"\s*\+\s*".*"': 
                ('medium', 'string_concat', '–ö–æ–Ω–∫–∞—Ç–µ–Ω–∞—Ü—ñ—è —Å—Ç—Ä–æ–∫ —É —Ü–∏–∫–ª—ñ'),
            
            # Deep Recursion
            r'def\s+\w+\s*\(.*\):\s*.*\w+\s*\(': 
                ('high', 'deep_recursion', '–ú–æ–∂–ª–∏–≤–æ –≥–ª–∏–±–æ–∫–∞ —Ä–µ–∫—É—Ä—Å—ñ—è'),
            
            # Memory Leaks
            r'__del__|gc\.collect': 
                ('high', 'memory_leak', '–ú–æ–∂–ª–∏–≤—ñ –≤–∏—Ç–æ–∫–∏ –ø–∞–º\'—è—Ç—ñ'),
        }
    
    def analyze_file(self, file_path: Path) -> List[PerformanceIssue]:
        """–ê–Ω–∞–ª—ñ–∑—É–≤–∞—Ç–∏ —Ñ–∞–π–ª –Ω–∞ –ø—Ä–æ–±–ª–µ–º–∏ –ø—Ä–æ–¥—É–∫—Ç–∏–≤–Ω–æ—Å—Ç—ñ"""
        issues = []
        
        try:
            with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                content = f.read()
                lines = content.split('\n')
            
            # –ü–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ –¥–æ–≤–∂–∏–Ω—É —Ñ—É–Ω–∫—Ü—ñ–π
            for line_num, line in enumerate(lines, 1):
                # –ü—Ä–æ–ø—É—Å–∫–∞—î–º–æ –∫–æ–º–µ–Ω—Ç–∞—Ä—ñ
                if line.strip().startswith('#') or line.strip().startswith('//'):
                    continue
                
                # –ü–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ –¥–æ–≤–≥—ñ —Ä—è–¥–∫–∏
                if len(line) > 120:
                    issues.append(PerformanceIssue(
                        'low', 'long_line', 
                        f'–î–æ–≤–≥–∏–π —Ä—è–¥–æ–∫ ({len(line)} —Å–∏–º–≤–æ–ª—ñ–≤)', 
                        line_num
                    ))
                
                # –ü–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ –≤–∫–ª–∞–¥–µ–Ω—ñ—Å—Ç—å
                indent = len(line) - len(line.lstrip())
                if indent > 32:  # –ë—ñ–ª—å—à–µ 8 —Ä—ñ–≤–Ω—ñ–≤ –≤–∫–ª–∞–¥–µ–Ω–æ—Å—Ç—ñ
                    issues.append(PerformanceIssue(
                        'medium', 'deep_nesting',
                        f'–ì–ª–∏–±–æ–∫–∞ –≤–∫–ª–∞–¥–µ–Ω—ñ—Å—Ç—å ({indent // 4} —Ä—ñ–≤–Ω—ñ–≤)',
                        line_num
                    ))
            
            # –ü–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ –∑–∞–≥–∞–ª—å–Ω—ñ –ø—Ä–æ–±–ª–µ–º–∏
            if 'for' in content and 'append' in content:
                for line_num, line in enumerate(lines, 1):
                    if 'for' in line and any(lines[min(i, len(lines)-1)].strip().startswith(('append', 'extend')) 
                                            for i in range(line_num, min(line_num + 5, len(lines)))):
                        issues.append(PerformanceIssue(
                            'medium', 'loop_append',
                            'Append —É —Ü–∏–∫–ª—ñ - —Ä–æ–∑–≥–ª—è–Ω—É—Ç–∏ list comprehension',
                            line_num
                        ))
                        break
        
        except Exception as e:
            pass
        
        return issues
    
    def analyze_project(self, extensions: Optional[List[str]] = None) -> Dict[str, Any]:
        """–ê–Ω–∞–ª—ñ–∑—É–≤–∞—Ç–∏ –≤–µ—Å—å –ø—Ä–æ–µ–∫—Ç"""
        if extensions is None:
            extensions = ['.py', '.js', '.ts', '.jsx', '.tsx']
        
        all_issues = []
        files_analyzed = 0
        
        for file_path in self.project_root.rglob('*'):
            if file_path.suffix not in extensions:
                continue
            
            # –ü—Ä–æ–ø—É—Å–∫–∞—î–º–æ node_modules, __pycache__ —Ç–æ—â–æ
            if any(part in file_path.parts for part in ['node_modules', '__pycache__', '.git']):
                continue
            
            files_analyzed += 1
            issues = self.analyze_file(file_path)
            
            for issue in issues:
                all_issues.append({
                    "file": str(file_path.relative_to(self.project_root)),
                    **issue.to_dict()
                })
        
        # –ì—Ä—É–ø—É—î–º–æ –∑–∞ —Ç–∏–ø–æ–º
        by_type = {}
        for issue in all_issues:
            issue_type = issue['type']
            if issue_type not in by_type:
                by_type[issue_type] = []
            by_type[issue_type].append(issue)
        
        # –ì—Ä—É–ø—É—î–º–æ –∑–∞ severity
        by_severity = {}
        for issue in all_issues:
            severity = issue['severity']
            if severity not in by_severity:
                by_severity[severity] = []
            by_severity[severity].append(issue)
        
        return {
            "files_analyzed": files_analyzed,
            "total_issues": len(all_issues),
            "by_severity": {k: len(v) for k, v in by_severity.items()},
            "by_type": {k: len(v) for k, v in by_type.items()},
            "issues": all_issues[:20],
            "critical_count": len(by_severity.get('critical', [])),
            "high_count": len(by_severity.get('high', [])),
        }
    
    def get_recommendations(self) -> List[str]:
        """–û—Ç—Ä–∏–º–∞—Ç–∏ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ—ó –¥–ª—è –æ–ø—Ç–∏–º—ñ–∑–∞—Ü—ñ—ó"""
        return [
            "üîÑ –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–π—Ç–µ list comprehension –∑–∞–º—ñ—Å—Ç—å append —É —Ü–∏–∫–ª–∞—Ö",
            "‚ö° –ö–µ—à—É–π—Ç–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏ regex –∫–æ–º–ø—ñ–ª—è—Ü—ñ—ó",
            "üîó –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–π—Ç–µ –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ñ –æ–ø–µ—Ä–∞—Ü—ñ—ó –¥–ª—è I/O",
            "üéØ –£–Ω–∏–∫–∞–π—Ç–µ –≥–ª–∏–±–æ–∫–æ—ó –≤–∫–ª–∞–¥–µ–Ω–æ—Å—Ç—ñ (max 4-5 —Ä—ñ–≤–Ω—ñ–≤)",
            "üìä –ü—Ä–æ—Ñ—ñ–ª—é–π—Ç–µ –∫–æ–¥ –ø–µ—Ä–µ–¥ –æ–ø—Ç–∏–º—ñ–∑–∞—Ü—ñ—î—é",
            "üíæ –ó–≤—ñ–ª—å–Ω—è–π—Ç–µ –ø–∞–º'—è—Ç—å –¥–ª—è –≤–µ–ª–∏–∫–∏—Ö —Å—Ç—Ä—É–∫—Ç—É—Ä –¥–∞–Ω–∏—Ö",
            "üîç –£–Ω–∏–∫–∞–π—Ç–µ N+1 query problems –∑ –±–∞—Ç—á-–∑–∞–ø–∏—Ç–∞–º–∏",
            "‚è±Ô∏è –í—Å—Ç–∞–Ω–æ–≤—ñ—Ç—å —Ç–∞–π–º–∞—É—Ç–∏ –¥–ª—è –∑–æ–≤–Ω—ñ—à–Ω—ñ—Ö –∑–∞–ø–∏—Ç—ñ–≤",
        ]


if __name__ == "__main__":
    analyzer = PerformanceAnalyzer(Path('.'))
    result = analyzer.analyze_project()
    
    print("‚ö° Performance Analysis Results")
    print(f"Files analyzed: {result['files_analyzed']}")
    print(f"Total issues: {result['total_issues']}")
    print(f"Critical: {result['critical_count']}")
    print(f"High: {result['high_count']}")
    print("\nüìã Recommendations:")
    for rec in analyzer.get_recommendations():
        print(f"  {rec}")
