2025-10-29 00:21:04,884 [ukrainian-tts-server] INFO: Python executable: /Users/dev/Documents/GitHub/atlas4/web/venv/bin/python3
2025-10-29 00:21:04,884 [ukrainian-tts-server] INFO: VIRTUAL_ENV/CONDA_PREFIX: /Users/dev/Documents/GitHub/atlas4/web/venv
2025-10-29 00:21:04,884 [ukrainian-tts-server] INFO: sys.path (first entries): ['/Users/dev/Documents/GitHub/atlas4/ukrainian-tts', '/Users/dev/.pyenv/versions/3.11.13/lib/python311.zip', '/Users/dev/.pyenv/versions/3.11.13/lib/python3.11', '/Users/dev/.pyenv/versions/3.11.13/lib/python3.11/lib-dynload', '/Users/dev/Documents/GitHub/atlas4/web/venv/lib/python3.11/site-packages']
2025-10-29 00:21:04,884 [ukrainian-tts-server] INFO: Initializing Ukrainian TTS on device: mps
/Users/dev/Documents/GitHub/atlas4/web/venv/lib/python3.11/site-packages/pyworld/__init__.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
  import pkg_resources
/Users/dev/Documents/GitHub/atlas4/web/venv/lib/python3.11/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  return self.fget.__get__(instance, owner)()
2025-10-29 00:21:07,513 [stanza] INFO: Loading these models for language: uk (Ukrainian):
=========================
| Processor | Package   |
-------------------------
| tokenize  | iu        |
| mwt       | iu        |
| pos       | iu_charlm |
=========================

2025-10-29 00:21:07,513 [stanza] INFO: Using device: cpu
2025-10-29 00:21:07,513 [stanza] INFO: Loading: tokenize
2025-10-29 00:21:07,652 [stanza] INFO: Loading: mwt
2025-10-29 00:21:07,655 [stanza] INFO: Loading: pos
2025-10-29 00:21:08,594 [stanza] INFO: Done loading processors!
2025-10-29 00:21:08,639 [root] INFO: Vocabulary size: 48
/Users/dev/Documents/GitHub/atlas4/web/venv/lib/python3.11/site-packages/torch/nn/utils/weight_norm.py:30: UserWarning: torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.
  warnings.warn("torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.")
2025-10-29 00:21:09,420 [root] INFO: Extractor:
LogMelFbank(
  (stft): Stft(n_fft=1024, win_length=1024, hop_length=256, center=True, normalized=False, onesided=True)
  (logmel): LogMel(sr=22050, n_fft=1024, n_mels=80, fmin=80, fmax=7600, htk=False)
)
2025-10-29 00:21:09,420 [root] INFO: Normalizer:
GlobalMVN(stats_file=feats_stats.npz, norm_means=True, norm_vars=True)
2025-10-29 00:21:09,421 [root] INFO: TTS:
JointText2Wav(
  (generator): ModuleDict(
    (text2mel): Tacotron2(
      (enc): Encoder(
        (embed): Embedding(48, 512, padding_idx=0)
        (convs): ModuleList(
          (0-2): 3 x Sequential(
            (0): Conv1d(512, 512, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)
            (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
            (3): Dropout(p=0.5, inplace=False)
          )
        )
        (blstm): LSTM(512, 256, batch_first=True, bidirectional=True)
      )
      (projection): Linear(in_features=192, out_features=512, bias=True)
      (dec): Decoder(
        (att): AttLoc(
          (mlp_enc): Linear(in_features=512, out_features=512, bias=True)
          (mlp_dec): Linear(in_features=1024, out_features=512, bias=False)
          (mlp_att): Linear(in_features=32, out_features=512, bias=False)
          (loc_conv): Conv2d(1, 32, kernel_size=(1, 31), stride=(1, 1), padding=(0, 15), bias=False)
          (gvec): Linear(in_features=512, out_features=1, bias=True)
        )
        (lstm): ModuleList(
          (0): ZoneOutCell(
            (cell): LSTMCell(768, 1024)
          )
          (1): ZoneOutCell(
            (cell): LSTMCell(1024, 1024)
          )
        )
        (prenet): Prenet(
          (prenet): ModuleList(
            (0): Sequential(
              (0): Linear(in_features=80, out_features=256, bias=True)
              (1): ReLU()
            )
            (1): Sequential(
              (0): Linear(in_features=256, out_features=256, bias=True)
              (1): ReLU()
            )
          )
        )
        (postnet): Postnet(
          (postnet): ModuleList(
            (0): Sequential(
              (0): Conv1d(80, 512, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)
              (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Tanh()
              (3): Dropout(p=0.5, inplace=False)
            )
            (1-3): 3 x Sequential(
              (0): Conv1d(512, 512, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)
              (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Tanh()
              (3): Dropout(p=0.5, inplace=False)
            )
            (4): Sequential(
              (0): Conv1d(512, 80, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)
              (1): BatchNorm1d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Dropout(p=0.5, inplace=False)
            )
          )
        )
        (feat_out): Linear(in_features=1536, out_features=80, bias=False)
        (prob_out): Linear(in_features=1536, out_features=1, bias=True)
      )
      (taco2_loss): Tacotron2Loss(
        (l1_criterion): L1Loss()
        (mse_criterion): MSELoss()
        (bce_criterion): BCEWithLogitsLoss()
      )
      (attn_loss): GuidedAttentionLoss()
    )
    (vocoder): HiFiGANGenerator(
      (input_conv): Conv1d(80, 512, kernel_size=(7,), stride=(1,), padding=(3,))
      (upsamples): ModuleList(
        (0): Sequential(
          (0): LeakyReLU(negative_slope=0.1)
          (1): ConvTranspose1d(512, 256, kernel_size=(16,), stride=(8,), padding=(4,))
        )
        (1): Sequential(
          (0): LeakyReLU(negative_slope=0.1)
          (1): ConvTranspose1d(256, 128, kernel_size=(16,), stride=(8,), padding=(4,))
        )
        (2): Sequential(
          (0): LeakyReLU(negative_slope=0.1)
          (1): ConvTranspose1d(128, 64, kernel_size=(4,), stride=(2,), padding=(1,))
        )
        (3): Sequential(
          (0): LeakyReLU(negative_slope=0.1)
          (1): ConvTranspose1d(64, 32, kernel_size=(4,), stride=(2,), padding=(1,))
        )
      )
      (blocks): ModuleList(
        (0): ResidualBlock(
          (convs1): ModuleList(
            (0): Sequential(
              (0): LeakyReLU(negative_slope=0.1)
              (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))
            )
            (1): Sequential(
              (0): LeakyReLU(negative_slope=0.1)
              (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
            )
            (2): Sequential(
              (0): LeakyReLU(negative_slope=0.1)
              (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))
            )
          )
          (convs2): ModuleList(
            (0-2): 3 x Sequential(
              (0): LeakyReLU(negative_slope=0.1)
              (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))
            )
          )
        )
        (1): ResidualBlock(
          (convs1): ModuleList(
            (0): Sequential(
              (0): LeakyReLU(negative_slope=0.1)
              (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,))
            )
            (1): Sequential(
              (0): LeakyReLU(negative_slope=0.1)
              (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))
            )
            (2): Sequential(
              (0): LeakyReLU(negative_slope=0.1)
              (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))
            )
          )
          (convs2): ModuleList(
            (0-2): 3 x Sequential(
              (0): LeakyReLU(negative_slope=0.1)
              (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,))
            )
          )
        )
        (2): ResidualBlock(
          (convs1): ModuleList(
            (0): Sequential(
              (0): LeakyReLU(negative_slope=0.1)
              (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(5,))
            )
            (1): Sequential(
              (0): LeakyReLU(negative_slope=0.1)
              (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))
            )
            (2): Sequential(
              (0): LeakyReLU(negative_slope=0.1)
              (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))
            )
          )
          (convs2): ModuleList(
            (0-2): 3 x Sequential(
              (0): LeakyReLU(negative_slope=0.1)
              (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(5,))
            )
          )
        )
        (3): ResidualBlock(
          (convs1): ModuleList(
            (0): Sequential(
              (0): LeakyReLU(negative_slope=0.1)
              (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))
            )
            (1): Sequential(
              (0): LeakyReLU(negative_slope=0.1)
              (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
            )
            (2): Sequential(
              (0): LeakyReLU(negative_slope=0.1)
              (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))
            )
          )
          (convs2): ModuleList(
            (0-2): 3 x Sequential(
              (0): LeakyReLU(negative_slope=0.1)
              (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))
            )
          )
        )
        (4): ResidualBlock(
          (convs1): ModuleList(
            (0): Sequential(
              (0): LeakyReLU(negative_slope=0.1)
              (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,))
            )
            (1): Sequential(
              (0): LeakyReLU(negative_slope=0.1)
              (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))
            )
            (2): Sequential(
              (0): LeakyReLU(negative_slope=0.1)
              (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))
            )
          )
          (convs2): ModuleList(
            (0-2): 3 x Sequential(
              (0): LeakyReLU(negative_slope=0.1)
              (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,))
            )
          )
        )
        (5): ResidualBlock(
          (convs1): ModuleList(
            (0): Sequential(
              (0): LeakyReLU(negative_slope=0.1)
              (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(5,))
            )
            (1): Sequential(
              (0): LeakyReLU(negative_slope=0.1)
              (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))
            )
            (2): Sequential(
              (0): LeakyReLU(negative_slope=0.1)
              (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))
            )
          )
          (convs2): ModuleList(
            (0-2): 3 x Sequential(
              (0): LeakyReLU(negative_slope=0.1)
              (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(5,))
            )
          )
        )
        (6): ResidualBlock(
          (convs1): ModuleList(
            (0): Sequential(
              (0): LeakyReLU(negative_slope=0.1)
              (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))
            )
            (1): Sequential(
              (0): LeakyReLU(negative_slope=0.1)
              (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
            )
            (2): Sequential(
              (0): LeakyReLU(negative_slope=0.1)
              (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))
            )
          )
          (convs2): ModuleList(
            (0-2): 3 x Sequential(
              (0): LeakyReLU(negative_slope=0.1)
              (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))
            )
          )
        )
        (7): ResidualBlock(
          (convs1): ModuleList(
            (0): Sequential(
              (0): LeakyReLU(negative_slope=0.1)
              (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(3,))
            )
            (1): Sequential(
              (0): LeakyReLU(negative_slope=0.1)
              (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))
            )
            (2): Sequential(
              (0): LeakyReLU(negative_slope=0.1)
              (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))
            )
          )
          (convs2): ModuleList(
            (0-2): 3 x Sequential(
              (0): LeakyReLU(negative_slope=0.1)
              (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(3,))
            )
          )
        )
        (8): ResidualBlock(
          (convs1): ModuleList(
            (0): Sequential(
              (0): LeakyReLU(negative_slope=0.1)
              (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(5,))
            )
            (1): Sequential(
              (0): LeakyReLU(negative_slope=0.1)
              (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))
            )
            (2): Sequential(
              (0): LeakyReLU(negative_slope=0.1)
              (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))
            )
          )
          (convs2): ModuleList(
            (0-2): 3 x Sequential(
              (0): LeakyReLU(negative_slope=0.1)
              (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(5,))
            )
          )
        )
        (9): ResidualBlock(
          (convs1): ModuleList(
            (0): Sequential(
              (0): LeakyReLU(negative_slope=0.1)
              (1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))
            )
            (1): Sequential(
              (0): LeakyReLU(negative_slope=0.1)
              (1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
            )
            (2): Sequential(
              (0): LeakyReLU(negative_slope=0.1)
              (1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))
            )
          )
          (convs2): ModuleList(
            (0-2): 3 x Sequential(
              (0): LeakyReLU(negative_slope=0.1)
              (1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))
            )
          )
        )
        (10): ResidualBlock(
          (convs1): ModuleList(
            (0): Sequential(
              (0): LeakyReLU(negative_slope=0.1)
              (1): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(3,))
            )
            (1): Sequential(
              (0): LeakyReLU(negative_slope=0.1)
              (1): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))
            )
            (2): Sequential(
              (0): LeakyReLU(negative_slope=0.1)
              (1): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))
            )
          )
          (convs2): ModuleList(
            (0-2): 3 x Sequential(
              (0): LeakyReLU(negative_slope=0.1)
              (1): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(3,))
            )
          )
        )
        (11): ResidualBlock(
          (convs1): ModuleList(
            (0): Sequential(
              (0): LeakyReLU(negative_slope=0.1)
              (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(5,))
            )
            (1): Sequential(
              (0): LeakyReLU(negative_slope=0.1)
              (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))
            )
            (2): Sequential(
              (0): LeakyReLU(negative_slope=0.1)
              (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))
            )
          )
          (convs2): ModuleList(
            (0-2): 3 x Sequential(
              (0): LeakyReLU(negative_slope=0.1)
              (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(5,))
            )
          )
        )
      )
      (output_conv): Sequential(
        (0): LeakyReLU(negative_slope=0.01)
        (1): Conv1d(32, 1, kernel_size=(7,), stride=(1,), padding=(3,))
        (2): Tanh()
      )
    )
  )
  (discriminator): HiFiGANMultiScaleMultiPeriodDiscriminator(
    (msd): HiFiGANMultiScaleDiscriminator(
      (discriminators): ModuleList(
        (0-2): 3 x HiFiGANScaleDiscriminator(
          (layers): ModuleList(
            (0): Sequential(
              (0): Conv1d(1, 128, kernel_size=(15,), stride=(1,), padding=(7,))
              (1): LeakyReLU(negative_slope=0.1)
            )
            (1): Sequential(
              (0): Conv1d(128, 128, kernel_size=(41,), stride=(4,), padding=(20,), groups=4)
              (1): LeakyReLU(negative_slope=0.1)
            )
            (2): Sequential(
              (0): Conv1d(128, 256, kernel_size=(41,), stride=(4,), padding=(20,), groups=16)
              (1): LeakyReLU(negative_slope=0.1)
            )
            (3): Sequential(
              (0): Conv1d(256, 512, kernel_size=(41,), stride=(4,), padding=(20,), groups=16)
              (1): LeakyReLU(negative_slope=0.1)
            )
            (4): Sequential(
              (0): Conv1d(512, 1024, kernel_size=(41,), stride=(4,), padding=(20,), groups=16)
              (1): LeakyReLU(negative_slope=0.1)
            )
            (5): Sequential(
              (0): Conv1d(1024, 1024, kernel_size=(41,), stride=(1,), padding=(20,), groups=16)
              (1): LeakyReLU(negative_slope=0.1)
            )
            (6): Sequential(
              (0): Conv1d(1024, 1024, kernel_size=(5,), stride=(1,), padding=(2,))
              (1): LeakyReLU(negative_slope=0.1)
            )
            (7): Conv1d(1024, 1, kernel_size=(3,), stride=(1,), padding=(1,))
          )
        )
      )
      (pooling): AvgPool1d(kernel_size=(4,), stride=(2,), padding=(2,))
    )
    (mpd): HiFiGANMultiPeriodDiscriminator(
      (discriminators): ModuleList(
        (0-4): 5 x HiFiGANPeriodDiscriminator(
          (convs): ModuleList(
            (0): Sequential(
              (0): Conv2d(1, 32, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))
              (1): LeakyReLU(negative_slope=0.1)
            )
            (1): Sequential(
              (0): Conv2d(32, 128, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))
              (1): LeakyReLU(negative_slope=0.1)
            )
            (2): Sequential(
              (0): Conv2d(128, 512, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))
              (1): LeakyReLU(negative_slope=0.1)
            )
            (3): Sequential(
              (0): Conv2d(512, 1024, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))
              (1): LeakyReLU(negative_slope=0.1)
            )
            (4): Sequential(
              (0): Conv2d(1024, 1024, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
              (1): LeakyReLU(negative_slope=0.1)
            )
          )
          (output_conv): Conv2d(1024, 1, kernel_size=(2, 1), stride=(1, 1), padding=(1, 0))
        )
      )
    )
  )
  (generator_adv_loss): GeneratorAdversarialLoss()
  (discriminator_adv_loss): DiscriminatorAdversarialLoss()
  (feat_match_loss): FeatureMatchLoss()
  (mel_loss): MelSpectrogramLoss(
    (wav_to_mel): LogMelFbank(
      (stft): Stft(n_fft=1024, win_length=1024, hop_length=256, center=True, normalized=False, onesided=True)
      (logmel): LogMel(sr=22050, n_fft=1024, n_mels=80, fmin=0, fmax=11025.0, htk=False)
    )
  )
)
2025-10-29 00:21:09,693 [ukrainian-tts-server] INFO: Ukrainian TTS initialized successfully
2025-10-29 00:21:09,693 [ukrainian-tts-server] INFO: Ukrainian TTS Server initialized at 127.0.0.1:3001
2025-10-29 00:21:09,694 [ukrainian-tts-server] INFO: Starting Ukrainian TTS Server on 127.0.0.1:3001
2025-10-29 00:21:09,694 [ukrainian-tts-server] INFO: TTS ready: True
2025-10-29 00:21:09,694 [ukrainian-tts-server] INFO: Device: mps
downloading https://github.com/robinhad/ukrainian-tts/releases/download/v6.0.0
Found ../model.pth. Skipping download...
Found ../config.yaml. Skipping download...
Found ../spk_xvector.ark. Skipping download...
Found ../feats_stats.npz. Skipping download...
downloaded.
 * Serving Flask app 'tts_server'
 * Debug mode: off
2025-10-29 00:21:09,706 [werkzeug] INFO: [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:3001
2025-10-29 00:21:09,706 [werkzeug] INFO: [33mPress CTRL+C to quit[0m
2025-10-29 00:21:27,300 [werkzeug] INFO: 127.0.0.1 - - [29/Oct/2025 00:21:27] "OPTIONS /health HTTP/1.1" 200 -
2025-10-29 00:21:27,302 [werkzeug] INFO: 127.0.0.1 - - [29/Oct/2025 00:21:27] "GET /health HTTP/1.1" 200 -
2025-10-29 00:21:34,597 [werkzeug] INFO: 127.0.0.1 - - [29/Oct/2025 00:21:34] "OPTIONS /health HTTP/1.1" 200 -
2025-10-29 00:21:34,599 [werkzeug] INFO: 127.0.0.1 - - [29/Oct/2025 00:21:34] "GET /health HTTP/1.1" 200 -
2025-10-29 00:21:44,194 [werkzeug] INFO: 127.0.0.1 - - [29/Oct/2025 00:21:44] "OPTIONS /health HTTP/1.1" 200 -
2025-10-29 00:21:44,195 [werkzeug] INFO: 127.0.0.1 - - [29/Oct/2025 00:21:44] "GET /health HTTP/1.1" 200 -
2025-10-29 00:21:50,238 [werkzeug] INFO: 127.0.0.1 - - [29/Oct/2025 00:21:50] "OPTIONS /tts HTTP/1.1" 200 -
2025-10-29 00:21:50,240 [ukrainian-tts-server] INFO: TTS request: text='ÐŸÐ¸Ñ€Ð²Ñ–Ñ‚, Ñ‚Ð²Ð¾Ñ€Ñ‡Ðµ! Ð¯ Ñ‚ÑƒÑ‚, Ð³Ð¾Ñ‚Ð¾Ð²Ð¸Ð¹ Ð´Ð¾ Ð½Ð¾Ð²Ð¸Ñ… Ð·Ð²ÐµÑ€ÑˆÐµÐ½ÑŒ. ...', voice=mykyta, fx=none, length=65 chars
/Users/dev/Documents/GitHub/atlas4/web/venv/lib/python3.11/site-packages/espnet2/torch_utils/device_funcs.py:29: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:212.)
  return to_device(torch.from_numpy(data), device, dtype, non_blocking, copy)
/Users/dev/Documents/GitHub/atlas4/web/venv/lib/python3.11/site-packages/torch/nn/utils/weight_norm.py:26: UserWarning: The operator 'aten::_weight_norm_interface' is not currently supported on the MPS backend and will fall back to run on the CPU. This may have performance implications. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/mps/MPSFallback.mm:13.)
  return _weight_norm(v, g, self.dim)
2025-10-29 00:21:53,573 [werkzeug] INFO: 127.0.0.1 - - [29/Oct/2025 00:21:53] "POST /tts HTTP/1.1" 200 -
2025-10-29 00:22:07,004 [werkzeug] INFO: 127.0.0.1 - - [29/Oct/2025 00:22:07] "OPTIONS /tts HTTP/1.1" 200 -
2025-10-29 00:22:07,021 [ukrainian-tts-server] INFO: TTS request: text='Ð ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ð¸ ÑÐ°Ð¼Ð¾Ð°Ð½Ð°Ð»Ñ–Ð·Ñƒ: ÐžÑÑŒ Ñ‰Ð¾ Ñ Ð²Ñ–Ð´Ñ‡ÑƒÐ²Ð°ÑŽ Ð² ÑÐ²Ð¾Ñ—Ñ… ...', voice=mykyta, fx=none, length=723 chars
2025-10-29 00:22:35,035 [werkzeug] INFO: 127.0.0.1 - - [29/Oct/2025 00:22:35] "POST /tts HTTP/1.1" 200 -
2025-10-29 00:23:43,511 [werkzeug] INFO: 127.0.0.1 - - [29/Oct/2025 00:23:43] "OPTIONS /tts HTTP/1.1" 200 -
2025-10-29 00:23:43,520 [ukrainian-tts-server] INFO: TTS request: text='ÐŸÑ€Ð¸Ð²Ñ–Ñ‚! Ð¯ Ñ‰Ð¾Ð¹Ð½Ð¾ Ð·Ð°Ð²ÐµÑ€ÑˆÐ¸Ð² Ð³Ð»Ð¸Ð±Ð¾ÐºÐ¸Ð¹ ÑÐ°Ð¼Ð¾Ð°Ð½Ð°Ð»Ñ–Ð·. Ð ÐµÐ·Ñƒ...', voice=mykyta, fx=none, length=857 chars
2025-10-29 00:24:16,949 [werkzeug] INFO: 127.0.0.1 - - [29/Oct/2025 00:24:16] "POST /tts HTTP/1.1" 200 -
2025-10-29 00:25:36,032 [werkzeug] INFO: 127.0.0.1 - - [29/Oct/2025 00:25:36] "OPTIONS /tts HTTP/1.1" 200 -
2025-10-29 00:25:36,034 [ukrainian-tts-server] INFO: TTS request: text='Ð ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ð¸ ÑÐ°Ð¼Ð¾Ð°Ð½Ð°Ð»Ñ–Ð·Ñƒ: ÐžÑÑŒ Ñ‰Ð¾ Ñ Ð²Ñ–Ð´Ñ‡ÑƒÐ²Ð°ÑŽ Ð² ÑÐ²Ð¾Ñ—Ñ… ...', voice=mykyta, fx=none, length=723 chars
2025-10-29 00:26:05,418 [werkzeug] INFO: 127.0.0.1 - - [29/Oct/2025 00:26:05] "POST /tts HTTP/1.1" 200 -
2025-10-29 00:27:13,103 [werkzeug] INFO: 127.0.0.1 - - [29/Oct/2025 00:27:13] "OPTIONS /tts HTTP/1.1" 200 -
2025-10-29 00:27:13,105 [ukrainian-tts-server] INFO: TTS request: text='ÐŸÑ€Ð¸Ð²Ñ–Ñ‚! Ð¯ Ñ‰Ð¾Ð¹Ð½Ð¾ Ð·Ð°Ð²ÐµÑ€ÑˆÐ¸Ð² Ð³Ð»Ð¸Ð±Ð¾ÐºÐ¸Ð¹ ÑÐ°Ð¼Ð¾Ð°Ð½Ð°Ð»Ñ–Ð·. Ð ÐµÐ·Ñƒ...', voice=mykyta, fx=none, length=857 chars
2025-10-29 00:27:48,980 [werkzeug] INFO: 127.0.0.1 - - [29/Oct/2025 00:27:48] "POST /tts HTTP/1.1" 200 -
