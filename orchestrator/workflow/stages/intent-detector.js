/**
 * INTELLIGENT INTENT DETECTOR
 * –†–æ–∑—É–º—ñ—î —â–æ –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á —Ö–æ—á–µ, –Ω–µ —Ç—ñ–ª—å–∫–∏ –ø–æ –∫–ª—é—á–æ–≤–∏—Ö —Å–ª–æ–≤–∞—Ö
 * 
 * Created: 2025-11-03
 * Purpose: –ó–∞–º—ñ–Ω–∏—Ç–∏ –ø—Ä–∏–º—ñ—Ç–∏–≤–Ω–∏–π pattern matching –Ω–∞ —Å–ø—Ä–∞–≤–∂–Ω—î —Ä–æ–∑—É–º—ñ–Ω–Ω—è
 */

import axios from 'axios';
import logger from '../../utils/logger.js';
import GlobalConfig from '../../../config/index.js';
import modelChecker from '../../ai/model-availability-checker.js';

export class IntentDetector {
    constructor() {
        this.logger = logger;
        this.apiEndpoint = null;
        this.modelConfig = null;
        this._ensureConfig();
    }
    
    /**
     * Ensure configuration is loaded
     */
    _ensureConfig() {
        if (!this.modelConfig) {
            const apiConfig = GlobalConfig.MCP_MODEL_CONFIG?.apiEndpoint;
            
            if (!apiConfig || typeof apiConfig !== 'object') {
                this.logger.warn('[INTENT-DETECTOR] API config not found, using fallback');
                this.apiEndpoint = 'http://localhost:4000/v1/chat/completions';
            } else {
                this.apiEndpoint = (apiConfig.useFallback && apiConfig.fallback)
                    ? apiConfig.fallback
                    : (apiConfig.primary || 'http://localhost:4000/v1/chat/completions');
            }
            
            // Get model config from MCP_MODEL_CONFIG
            this.modelConfig = GlobalConfig.MCP_MODEL_CONFIG.getStageConfig('intent_detection');
            
            // Fallback if config not found
            if (!this.modelConfig) {
                this.logger.warn('[INTENT-DETECTOR] Stage config not found, using default');
                this.modelConfig = {
                    model: 'atlas-ministral-3b',
                    temperature: 0.1,
                    max_tokens: 150
                };
            }
            
            this.logger.info('[INTENT-DETECTOR] Initialized with model: ' + this.modelConfig.model, {
                temperature: this.modelConfig.temperature,
                max_tokens: this.modelConfig.max_tokens
            });
        }
    }
    
    /**
     * –î–í–û–•–†–Ü–í–ù–ï–í–ê –î–ï–¢–ï–ö–¶–Ü–Ø INTENT
     * Level 1: –®–≤–∏–¥–∫–∏–π keyword matching (0.1ms)
     * Level 2: LLM —Ä–æ–∑—É–º—ñ–Ω–Ω—è –∫–æ–Ω—Ç–µ–∫—Å—Ç—É (200-500ms)
     */
    async detectInterventionIntent(userMessage, analysisContext = {}) {
        const startTime = Date.now();
        
        // LEVEL 1: –®–≤–∏–¥–∫–∏–π keyword matching
        const keywordResult = this._detectKeywords(userMessage);
        if (keywordResult.detected) {
            this.logger.info('[INTENT-DETECTOR] ‚ö° Detected via keywords', {
                confidence: keywordResult.confidence,
                duration: Date.now() - startTime
            });
            return keywordResult;
        }
        
        // LEVEL 2: LLM intent analysis (—Ç—ñ–ª—å–∫–∏ —è–∫—â–æ —î –ø—Ä–æ–±–ª–µ–º–∏)
        const hasCriticalIssues = (analysisContext.criticalIssues || 0) > 0;
        const hasPerformanceIssues = (analysisContext.performanceIssues || 0) > 0;
        
        if (hasCriticalIssues || hasPerformanceIssues) {
            this.logger.info('[INTENT-DETECTOR] üß† Using LLM for semantic understanding');
            
            const llmResult = await this._detectLLMIntent(userMessage, analysisContext);
            
            this.logger.info('[INTENT-DETECTOR] LLM result', {
                detected: llmResult.detected,
                confidence: llmResult.confidence,
                reasoning: llmResult.reasoning,
                duration: Date.now() - startTime
            });
            
            // FIXED 03.11.2025: –Ø–∫—â–æ LLM fallback, –ø–æ–≤–µ—Ä—Ç–∞—î–º–æ keyword —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            if (llmResult.method === 'llm-fallback' && keywordResult.detected) {
                this.logger.info('[INTENT-DETECTOR] ‚úÖ LLM failed, using keyword result as fallback', {
                    keyword: keywordResult.matchedPattern,
                    confidence: keywordResult.confidence
                });
                return keywordResult;
            }
            
            return llmResult;
        }
        
        // No intervention needed
        return {
            detected: false,
            method: 'none',
            confidence: 0,
            reasoning: 'No intervention keywords and no critical issues'
        };
    }
    
    /**
     * LEVEL 1: –®–≤–∏–¥–∫–∞ –¥–µ—Ç–µ–∫—Ü—ñ—è –ø–æ –∫–ª—é—á–æ–≤–∏—Ö —Å–ª–æ–≤–∞—Ö
     */
    _detectKeywords(userMessage) {
        const msg = userMessage.toLowerCase();
        
        const interventionPatterns = [
            // –ü—Ä—è–º–µ –≤–∏–ø—Ä–∞–≤–ª–µ–Ω–Ω—è
            { pattern: /\b(–≤–∏–ø—Ä–∞–≤|fix|repair|–ø–æ–ª–∞–≥–æ–¥—å)\b/i, confidence: 0.95 },
            { pattern: /\b(–≤–∏–ø—Ä–∞–≤ —Å–µ–±–µ|fix yourself|repair yourself)\b/i, confidence: 0.99 },
            
            // FIXED 2025-11-03: –î–æ–¥–∞–Ω–æ "–ø—Ä–∏—Å—Ç—É–ø–∞–π –¥–æ –≤–∏–ø—Ä–∞–≤–ª–µ–Ω–Ω—è" (–±–µ–∑ \b –ø—ñ—Å–ª—è –≥—Ä—É–ø–∏)
            { pattern: /(–ø—Ä–∏—Å—Ç—É–ø|proceed|—Ä–æ–∑–ø–æ—á–∏–Ω|start|–ø–æ—á–Ω).*(–≤–∏–ø—Ä–∞–≤|fix|–ª—ñ–∫—É|heal)/i, confidence: 0.97 },
            { pattern: /(–ø—Ä–∏—Å—Ç—É–ø–∞–π|–ø–æ—á–∏–Ω–∞–π)/i, confidence: 0.92 },
            
            // –ó–º—ñ–Ω–∏ –∫–æ–¥—É
            { pattern: /\b(–∑–º—ñ–Ω–∏|change|–º–æ–¥–∏—Ñ—ñ–∫|modify|–æ–Ω–æ–≤–∏—Ç–∏|update)\b.*\b(–∫–æ–¥|code|—Å–µ–±–µ|yourself)\b/i, confidence: 0.90 },
            
            // –°–∞–º–æ-–ª—ñ–∫—É–≤–∞–Ω–Ω—è
            { pattern: /\b(–≤–∏–ª—ñ–∫—É–π|heal|—Å–∞–º–æ–ª—ñ–∫—É–≤–∞–Ω–Ω—è|self-heal)\b/i, confidence: 0.92 },
            { pattern: /\b(—Å–∞–º–æ –≤–∏–ø—Ä–∞–≤|self-repair|—Å–∞–º–æ-–≤–∏–ø—Ä–∞–≤–ª–µ–Ω–Ω—è)\b/i, confidence: 0.95 },
            
            // –ü–æ–∫—Ä–∞—â–µ–Ω–Ω—è
            { pattern: /\b(–≤–¥–æ—Å–∫–æ–Ω–∞–ª|improve|–ø–æ–∫—Ä–∞—â|enhance)\b.*\b(—Å–µ–±–µ|yourself)\b/i, confidence: 0.88 },
            
            // –ó–∞—Å—Ç–æ—Å—É–≤–∞–Ω–Ω—è –∑–º—ñ–Ω
            { pattern: /\b(–≤–Ω–µ—Å—Ç–∏ –∑–º—ñ–Ω–∏|apply changes|apply fixes|–∑–∞—Å—Ç–æ—Å—É–π)\b/i, confidence: 0.93 },
            
            // –†–µ—Ñ–∞–∫—Ç–æ—Ä–∏–Ω–≥
            { pattern: /\b(—Ä–µ—Ñ–∞–∫—Ç–æ—Ä|refactor)\b.*\b(—Å–µ–±–µ|yourself|—Å–≤—ñ–π –∫–æ–¥|your code)\b/i, confidence: 0.85 }
        ];
        
        for (const { pattern, confidence } of interventionPatterns) {
            if (pattern.test(msg)) {
                const match = msg.match(pattern);
                return {
                    detected: true,
                    method: 'keyword',
                    confidence: confidence,
                    matchedPattern: match[0],
                    reasoning: `Matched keyword pattern: "${match[0]}"`
                };
            }
        }
        
        return { detected: false, method: 'keyword', confidence: 0 };
    }
    
    /**
     * LEVEL 2: LLM —Å–µ–º–∞–Ω—Ç–∏—á–Ω–µ —Ä–æ–∑—É–º—ñ–Ω–Ω—è
     */
    async _detectLLMIntent(userMessage, analysisContext) {
        try {
            const prompt = this._buildIntentPrompt(userMessage, analysisContext);
            
            // ADDED 2025-11-08: Use axios with fallback on any error
            let response;
            let usedModel = this.modelConfig.model;
            
            try {
                response = await axios.post(this.apiEndpoint, {
                    model: usedModel,
                    messages: [{ role: 'user', content: prompt }],
                    temperature: this.modelConfig.temperature,
                    max_tokens: this.modelConfig.max_tokens,
                    response_format: { type: 'json_object' }
                }, {
                    timeout: 10000
                });
            } catch (primaryError) {
                this.logger.warn('[INTENT-DETECTOR] Primary model failed, trying alternatives');
                
                // FIXED 2025-11-10: Use cached fetchAvailableModels instead of direct GET /v1/models
                const apiModels = await modelChecker.fetchAvailableModels();
                
                if (!apiModels || apiModels.length === 0) {
                    throw new Error('No models available from API');
                }
                
                // CRITICAL 2025-11-10: Limit to first 5 models to prevent burst
                const modelsToTry = apiModels.slice(0, 5).map(m => m.id);
                this.logger.info(`[INTENT-DETECTOR] Checking ${modelsToTry.length} models (limited from ${apiModels.length})`);
                
                for (const altModel of modelsToTry) {
                    if (altModel === usedModel) continue;
                    
                    const modelResult = await modelChecker.getAvailableModel(altModel, null, 'intent');
                    if (modelResult.available) {
                        usedModel = altModel;
                        response = await axios.post(this.apiEndpoint, {
                            model: usedModel,
                            messages: [{ role: 'user', content: prompt }],
                            temperature: this.modelConfig.temperature,
                            max_tokens: this.modelConfig.max_tokens,
                            response_format: { type: 'json_object' }
                        }, {
                            timeout: 10000
                        });
                        break;
                    }
                }
                
                if (!response) throw primaryError;
            }
            
            const data = response.data;
            const content = data.choices?.[0]?.message?.content;
            
            if (!content) {
                throw new Error('Empty LLM response');
            }
            
            const intent = JSON.parse(content);
            
            return {
                detected: intent.wants_intervention && intent.confidence >= 70,
                method: 'llm',
                confidence: intent.confidence / 100,
                reasoning: intent.reasoning,
                semanticUnderstanding: intent.semantic_understanding
            };
            
        } catch (error) {
            this.logger.warn('[INTENT-DETECTOR] LLM detection failed, fallback to false', {
                error: error.message
            });
            return {
                detected: false,
                method: 'llm-fallback',
                confidence: 0,
                reasoning: `LLM error: ${error.message}`
            };
        }
    }
    
    /**
     * Build prompt for LLM intent detection
     */
    _buildIntentPrompt(userMessage, analysisContext) {
        return `–ê–Ω–∞–ª—ñ–∑—É–π —á–∏ –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á –ø—Ä–æ—Å–∏—Ç—å Atlas –≤–∏–ø—Ä–∞–≤–∏—Ç–∏ —Å–µ–±–µ (code intervention).

USER MESSAGE: "${userMessage}"

CONTEXT:
- –ó–Ω–∞–π–¥–µ–Ω–æ ${analysisContext.criticalIssues || 0} –∫—Ä–∏—Ç–∏—á–Ω–∏—Ö –ø—Ä–æ–±–ª–µ–º
- –ó–Ω–∞–π–¥–µ–Ω–æ ${analysisContext.performanceIssues || 0} –ø—Ä–æ–±–ª–µ–º –ø—Ä–æ–¥—É–∫—Ç–∏–≤–Ω–æ—Å—Ç—ñ
- –°–∏—Å—Ç–µ–º–∞ –º–∞—î ${analysisContext.suggestions || 0} —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ–π –¥–ª—è –ø–æ–∫—Ä–∞—â–µ–Ω–Ω—è

–¢–í–û–Ñ –ó–ê–í–î–ê–ù–ù–Ø:
–í–∏–∑–Ω–∞—á —á–∏ –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á –ø—Ä–æ—Å–∏—Ç—å Atlas –≤–∏–ø—Ä–∞–≤–∏—Ç–∏ —Å–µ–±–µ (–≤–Ω–µ—Å—Ç–∏ –∑–º—ñ–Ω–∏ –≤ –∫–æ–¥).

–ü–†–ò–ö–õ–ê–î–ò "wants_intervention = true":
- "–í–∏–ø—Ä–∞–≤ —Å–µ–±–µ"
- "–ó—Ä–æ–±–∏ —Å–µ–±–µ –∫—Ä–∞—â–∏–º"
- "–£—Å—É–Ω—å —Ü—ñ –±–∞–≥–∏"
- "–ü—Ä–æ—Ç–µ—Å—Ç—É–π —ñ –≤–∏–ø—Ä–∞–≤ –ø—Ä–æ–±–ª–µ–º–∏"
- "–ü–æ–∫—Ä–∞—â —Å–≤–æ—é —Ä–æ–±–æ—Ç—É"
- "–û–ø—Ç–∏–º—ñ–∑—É–π —Å–µ–±–µ"

–ü–†–ò–ö–õ–ê–î–ò "wants_intervention = false":
- "–Ø–∫ —Ç–∏ –ø—Ä–∞—Ü—é—î—à?"
- "–ü–æ–∫–∞–∂–∏ –º–µ–Ω—ñ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É"
- "–ü—Ä–æ–∞–Ω–∞–ª—ñ–∑—É–π —Å–µ–±–µ" (—Ç—ñ–ª—å–∫–∏ –∞–Ω–∞–ª—ñ–∑, –±–µ–∑ –≤–∏–ø—Ä–∞–≤–ª–µ–Ω–Ω—è)
- "–Ø–∫–∏–π —É —Ç–µ–±–µ —Å—Ç–∞–Ω?"

–í—ñ–¥–ø–æ–≤—ñ–¥—å –¢–Ü–õ–¨–ö–ò valid JSON:
{
  "wants_intervention": true/false,
  "confidence": 0-100,
  "reasoning": "—á–æ–º—É —Ç–∞–∫ –≤–∏—Ä—ñ—à–∏–≤ (1-2 —Ä–µ—á–µ–Ω–Ω—è)",
  "semantic_understanding": "—â–æ –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á –Ω–∞—Å–ø—Ä–∞–≤–¥—ñ —Ö–æ—á–µ"
}`;
    }
}

export default IntentDetector;
