# ===================================
# ATLAS v5.0 - Environment Configuration
# ===================================
# Copy this file to .env and configure your settings
# Last Updated: 2025-10-16 (v5.0 - Pure MCP Edition)

# === SYSTEM ===
NODE_ENV=production
BUILD_NUMBER=dev
LOG_LEVEL=info
FORCE_FREE_PORTS=true

# === LLM API CONFIGURATION (NEW v5.0) ===
# Primary LLM API endpoint (local)
LLM_API_ENDPOINT=http://localhost:4000/v1/chat/completions

# Fallback LLM API endpoint (ngrok tunnel for remote access)
# Example: https://bdd80b70a92d.ngrok-free.app/v1/chat/completions
LLM_API_FALLBACK_ENDPOINT=

# Enable fallback to remote API when local unavailable
LLM_API_USE_FALLBACK=true

# API timeout in milliseconds
LLM_API_TIMEOUT=60000

# === AI BACKEND CONFIGURATION ===
# v5.0: Pure MCP mode only
# Backend mode: 'mcp' (recommended)
AI_BACKEND_MODE=mcp

# Primary backend for task execution
AI_BACKEND_PRIMARY=mcp

# Disable fallback (strict mode for development/testing)
# - true: System will throw errors on failures (no fallback)
# - false: System will attempt fallback (production safe)
AI_BACKEND_DISABLE_FALLBACK=false

# === AI MODEL CONFIGURATION ===
# AI models for different stages (chat, analysis, classification)
AI_MODEL_CLASSIFICATION=atlas-ministral-3b
AI_TEMP_CLASSIFICATION=0.05
AI_MODEL_CHAT=atlas-mistral-medium-2505
AI_TEMP_CHAT=0.7
AI_MODEL_ANALYSIS=ext-mistral-codestral-2405
AI_TEMP_ANALYSIS=0.2
AI_MODEL_TTS_OPT=atlas-ministral-3b
AI_TEMP_TTS_OPT=0.15

# === MCP MODEL CONFIGURATION ===
# MCP workflow models for each stage
MCP_MODEL_MODE_SELECTION=atlas-ministral-3b
MCP_TEMP_MODE_SELECTION=0.05
MCP_MODEL_BACKEND_SELECTION=atlas-ministral-3b
MCP_TEMP_BACKEND_SELECTION=0.05
MCP_MODEL_CONTEXT_ENRICHMENT=atlas-gpt-4o
MCP_TEMP_CONTEXT_ENRICHMENT=0.3
MCP_MODEL_TODO_PLANNING=atlas-mistral-medium-2505
MCP_TEMP_TODO_PLANNING=0.3
MCP_MODEL_PLAN_TOOLS=atlas-gpt-4o
MCP_TEMP_PLAN_TOOLS=0.1
MCP_MODEL_VERIFICATION_ELIGIBILITY=atlas-ministral-3b
MCP_TEMP_VERIFICATION_ELIGIBILITY=0.1
MCP_MODEL_VERIFY_ITEM=atlas-mistral-small-2503
MCP_TEMP_VERIFY_ITEM=0.15
MCP_MODEL_ADJUST_TODO=atlas-mistral-medium-2505
MCP_TEMP_ADJUST_TODO=0.2
MCP_MODEL_REPLAN_TODO=atlas-mistral-medium-2505
MCP_TEMP_REPLAN_TODO=0.3
MCP_MODEL_FINAL_SUMMARY=atlas-ministral-3b
MCP_TEMP_FINAL_SUMMARY=0.5
MCP_MODEL_VISION=atlas-llama-3.2-11b-vision-instruct
MCP_TEMP_VISION=0.2
MCP_MODEL_VISION_FAST=atlas-llama-3.2-11b-vision-instruct
MCP_TEMP_VISION_FAST=0.2
MCP_MODEL_VISION_STRONG=atlas-llama-3.2-90b-vision-instruct
MCP_TEMP_VISION_STRONG=0.2
MCP_MODEL_VISION_FALLBACK=llama3.2-vision
MCP_MODEL_SERVER_SELECTION=atlas-ministral-3b
MCP_TEMP_SERVER_SELECTION=0.05
MCP_MODEL_STATE_ANALYSIS=atlas-ministral-3b
MCP_TEMP_STATE_ANALYSIS=0.1
MCP_MODEL_DEV_ANALYSIS=ext-mistral-codestral-latest
MCP_TEMP_DEV_ANALYSIS=0.2
MCP_TEMP_STATE_ANALYSIS=0.1
MCP_MODEL_SCREENSHOT_ADJ=atlas-phi-4-multimodal-instruct
MCP_TEMP_SCREENSHOT_ADJ=0.2
MCP_MODEL_VISUAL_CAPTURE_MODE=atlas-ministral-3b
MCP_TEMP_VISUAL_CAPTURE_MODE=0.1
MCP_MODEL_TTS_OPT=atlas-ministral-3b
MCP_TEMP_TTS_OPT=0.3

# === CHAT MEMORY CONFIGURATION (NEW 26.10.2025) ===
# Model for chat memory eligibility (intelligent decision if long-term memory is needed)
# Default: atlas-ai21-jamba-1.5-mini (ultra fast classification for memory decisions)
# Options: atlas-ai21-jamba-1.5-mini | atlas-ministral-3b | atlas-gpt-4o-mini
MCP_MODEL_CHAT_MEMORY_ELIGIBILITY=atlas-ai21-jamba-1.5-mini
MCP_TEMP_CHAT_MEMORY_ELIGIBILITY=0.1

# === MCP LLM VALIDATOR CONFIGURATION ===
# LLM model for MCP Tool Validator (safety and validation)
# Default: ext-mistral-codestral-2405 (code-specialized model for validation)
# Options: atlas-gpt-4o-mini | atlas-ministral-3b | ext-mistral-codestral-2405
MCP_LLM_MODEL=ext-mistral-codestral-2405
MCP_LLM_TEMPERATURE=0.1

# === SECURITY CONFIGURATION (NEW 21.10.2025) ===
# Enable/disable LLM Tool Validator
# Default: true (always validate for safety)
SECURITY_LLM_VALIDATOR_ENABLED=true

# Fallback behavior when validation fails
# Options: 'allow' (default) | 'deny'
SECURITY_VALIDATOR_FALLBACK=allow

# Enable/disable repetition checking
SECURITY_REPETITION_CHECK_ENABLED=true

# Maximum consecutive repetitions before blocking
SECURITY_MAX_CONSECUTIVE_REPETITIONS=3

# Maximum total calls per tool
SECURITY_MAX_TOTAL_CALLS=10

# Auto-block critical risk operations
SECURITY_AUTO_BLOCK_CRITICAL=true

# Auto-block high risk operations
SECURITY_AUTO_BLOCK_HIGH=true

# Show warnings for medium risk operations
SECURITY_WARN_ON_MEDIUM=true

# Log all validation attempts (for debugging)
SECURITY_LOG_ALL_VALIDATIONS=false

# Verbose logging for blocked operations
SECURITY_VERBOSE_BLOCKING=true

# Tool history configuration
SECURITY_TOOL_HISTORY_ENABLED=true
SECURITY_HISTORY_MAX_SIZE=100
SECURITY_HISTORY_CONTEXT_SIZE=5
SECURITY_HISTORY_PERSISTENT=false

# === GRISHA VERIFICATION CONFIGURATION (NEW 22.10.2025) ===
# Model for verification eligibility routing (visual vs MCP decision)
# Default: atlas-ministral-3b (fast classification for routing)
# Options: atlas-ministral-3b | atlas-mistral-small-2503 | atlas-gpt-4o-mini
MCP_MODEL_VERIFICATION_ELIGIBILITY=atlas-ministral-3b

# === AUTO-CORRECTION CONFIGURATION (NEW 30.10.2025) ===
# Enable/disable automatic correction of non-critical errors
# Default: true (auto-fix minor issues without password)
AUTO_CORRECTION_ENABLED=true

# Interval for auto-correction checks (milliseconds)
# Default: 300000 (5 minutes)
AUTO_CORRECTION_INTERVAL=300000

# Maximum number of auto-fixes per check
# Default: 5
AUTO_CORRECTION_MAX_FIXES=5

# Notification mode for auto-corrections
# Options: 'subtle' (brief mentions) | 'verbose' (detailed) | 'silent' (no notifications)
AUTO_CORRECTION_NOTIFY=subtle

# Enable Python SDK for auto-correction
# Default: true (if python_sdk MCP server is available)
MCP_PYTHON_SDK_ENABLED=true

# Enable Java SDK for auto-correction  
# Default: true (if java_sdk MCP server is available)
MCP_JAVA_SDK_ENABLED=true

# Temperature for verification eligibility (0.0-1.0)
# Default: 0.1 (low temperature for consistent routing decisions)
MCP_TEMP_VERIFICATION_ELIGIBILITY=0.1

# === MCP RETRY CONFIGURATION (NEW 18.10.2025) ===
# Maximum number of retry attempts for MCP operations
# Default: 3 (allows retries for transient failures)
MCP_MAX_ATTEMPTS=3

# Maximum retry attempts specifically for TODO item execution
# Default: 3 (allows Tetyana to retry tool planning on validation errors)
MCP_ITEM_MAX_ATTEMPTS=3

# Circuit breaker threshold (failures before opening circuit)
# Default: 3 (after 3 consecutive failures, circuit opens)
MCP_CIRCUIT_BREAKER_THRESHOLD=3

# Circuit breaker reset timeout in milliseconds
# Default: 60000 (60 seconds before attempting to close circuit)
MCP_CIRCUIT_BREAKER_RESET_MS=60000

# MCP operation timeout in milliseconds
# Default: 30000 (30 seconds per operation)
MCP_TIMEOUT_MS=30000

# Enable/disable exponential backoff for retries
# Default: true (enabled)
MCP_EXPONENTIAL_BACKOFF=true

# === TTS & VOICE ===
REAL_TTS_MODE=true
TTS_DEVICE=mps
TTS_PORT=3001

# TTS Text Segmentation (NEW 2025-11-02)
# Maximum chunk size for text segmentation (characters)
# Longer texts are split into chunks by paragraphs, then by sentences if needed
# Default: 800 (optimal for continuous speech without breaks)
ATLAS_TTS_MAX_CHUNK_SIZE=400

# === WHISPER CONFIGURATION ===
# Optimized for Mac Studio M1 MAX (Metal GPU)
WHISPER_BACKEND=cpp
WHISPER_DEVICE=metal
WHISPER_PORT=3002
WHISPER_CPP_BIN=/Users/dev/Documents/GitHub/atlas4/third_party/whisper.cpp.upstream/build/bin/whisper-cli
WHISPER_CPP_MODEL=/Users/dev/Documents/GitHub/atlas4/models/whisper/ggml-large-v3.bin
# Mac Studio M1 MAX optimizations:
WHISPER_CPP_NGL=20              # GPU layers (Metal acceleration)
WHISPER_CPP_THREADS=10          # M1 Max has 10 performance cores
WHISPER_CPP_DISABLE_GPU=false   # Keep Metal GPU enabled
WHISPER_SAMPLE_RATE=48000       # High quality audio (v5.0)

# === NETWORK PORTS ===
ORCHESTRATOR_PORT=5101
WEB_PORT=5001
FRONTEND_PORT=5001

# === LOCALIZATION CONFIGURATION (NEW 24.10.2025) ===
# User interface language
# Supported: uk (Ukrainian), en (English), es (Spanish), fr (French), de (German), pl (Polish), ru (Russian)
USER_LANGUAGE=uk

# Show system messages in chat (true/false)
# When false, only user-relevant messages are shown
SHOW_SYSTEM_MESSAGES=false

# System message verbosity level (0-3)
# 0 = None, 1 = Errors only, 2 = Warnings+Errors, 3 = All
SYSTEM_MESSAGE_LEVEL=1

# === FEATURES ===
# Mac Studio M1 MAX optimizations
USE_METAL_GPU=true              # Metal GPU for Whisper and TTS
OPTIMIZE_FOR_M1_MAX=true        # Enable M1 MAX specific optimizations
